{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences v 2.9 kebawah\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, Bidirectional, LSTM, GRU, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BIGU-CNN_TFIDF_UNIGRAM_BIGRAM_TRIGRAM_DROPOUT0.5\n",
    "Copyright @I Gde Bagus Janardana Abasan"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def process_data(test_size):\n",
    "  dataset = pd.read_csv('..//..//../data/data-for-test/dataset_kepolisian_clean_test.csv', usecols=['preprocess_final', 'label_fase_1'])\n",
    "  # COPY ONLY 100 data\n",
    "  # make data['label_fase_1'] to 0 and 1 binary classifier karena tensor hanya bisa input 0 =< label =< 1\n",
    "  dataset['label_fase_1'] = dataset['label_fase_1'].apply(lambda x: 1 if x == 'HS' else 0)\n",
    "\n",
    "  tf_idf_vec = TfidfVectorizer(use_idf=True, smooth_idf=False, ngram_range=(1,3), max_features=10000)\n",
    "\n",
    "  #   transform\n",
    "  tf_idf_data = tf_idf_vec.fit_transform(dataset['preprocess_final'])\n",
    "  x_final = pd.DataFrame(tf_idf_data.toarray(), columns=tf_idf_vec.get_feature_names_out())\n",
    "  y_final = dataset['label_fase_1'].copy()\n",
    "\n",
    "  # split data\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x_final, y_final, test_size=test_size, random_state=42)\n",
    "\n",
    "  return x_train, x_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def create_bigru_cnn_model(x_train, x_test, y_train, y_test, epochs, batch_size):\n",
    "  # BiGRU + CNN model\n",
    "  #reshape\n",
    "  X_train = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "  X_test = np.array(x_test).reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Bidirectional(GRU(input_shape=X_train.shape, units=32, return_sequences=True)))\n",
    "  model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "  model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(units=32, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(units=1, activation='sigmoid'))\n",
    "  model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.build(input_shape=(None, X_train.shape[1], 1))\n",
    "  model.summary()\n",
    "  model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)\n",
    "  loss = model.history.history['loss']\n",
    "  val_loss = model.history.history['val_loss']\n",
    "  print(\"=== MODEL EVALUATE TEST DATA ===\")\n",
    "  score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "  print()\n",
    "  print('Validation Accuracy:', score[1])\n",
    "  print('Validation Loss:', score[0])\n",
    "  print()\n",
    "\n",
    "  return model, loss, val_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def call():\n",
    "  x_train, x_test, y_train, y_test = process_data(test_size=0.2)\n",
    "  model, loss, val_loss = create_bigru_cnn_model(x_train, x_test, y_train, y_test, epochs=10, batch_size=64)\n",
    "  # predict\n",
    "  y_pred = model.predict(x_test)\n",
    "  print()\n",
    "\n",
    "  # confusion matrix\n",
    "  classreport = classification_report(y_test, y_pred.round(), digits=4)\n",
    "  print(classreport)\n",
    "  print()\n",
    "  accscore = accuracy_score(y_test, y_pred.round())\n",
    "  precscore = precision_score(y_test, y_pred.round())\n",
    "  recscore = recall_score(y_test, y_pred.round())\n",
    "  f1score = f1_score(y_test, y_pred.round())\n",
    "\n",
    "  return [accscore, precscore, recscore, f1score, loss, val_loss]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 10000, 64)        6720      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 10000, 32)         6176      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5000, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5000, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 160000)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                5120032   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,132,961\n",
      "Trainable params: 5,132,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 475s 4s/step - loss: 0.5620 - accuracy: 0.6855 - val_loss: 0.4640 - val_accuracy: 0.7686\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 374s 3s/step - loss: 0.3901 - accuracy: 0.8199 - val_loss: 0.4732 - val_accuracy: 0.7676\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 348s 3s/step - loss: 0.3080 - accuracy: 0.8647 - val_loss: 0.4999 - val_accuracy: 0.7681\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 350s 3s/step - loss: 0.2340 - accuracy: 0.8963 - val_loss: 0.5940 - val_accuracy: 0.7639\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 343s 3s/step - loss: 0.1706 - accuracy: 0.9252 - val_loss: 0.7317 - val_accuracy: 0.7582\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 360s 3s/step - loss: 0.1247 - accuracy: 0.9467 - val_loss: 0.9413 - val_accuracy: 0.7577\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 363s 3s/step - loss: 0.0885 - accuracy: 0.9629 - val_loss: 1.0878 - val_accuracy: 0.7551\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 360s 3s/step - loss: 0.0642 - accuracy: 0.9730 - val_loss: 1.3264 - val_accuracy: 0.7582\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 392s 3s/step - loss: 0.0478 - accuracy: 0.9797 - val_loss: 1.5339 - val_accuracy: 0.7525\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 373s 3s/step - loss: 0.0462 - accuracy: 0.9802 - val_loss: 1.8843 - val_accuracy: 0.7530\n",
      "=== MODEL EVALUATE TEST DATA ===\n",
      "\n",
      "Validation Accuracy: 0.7529963254928589\n",
      "Validation Loss: 1.8842920064926147\n",
      "\n",
      "60/60 [==============================] - 77s 1s/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7380    0.7942    0.7651       972\n",
      "           1     0.7709    0.7107    0.7396       947\n",
      "\n",
      "    accuracy                         0.7530      1919\n",
      "   macro avg     0.7545    0.7525    0.7523      1919\n",
      "weighted avg     0.7543    0.7530    0.7525      1919\n",
      "\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_1 (Bidirectio  (None, 10000, 64)        6720      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 10000, 32)         6176      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 5000, 32)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5000, 32)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 160000)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                5120032   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,132,961\n",
      "Trainable params: 5,132,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 423s 3s/step - loss: 0.5435 - accuracy: 0.7016 - val_loss: 0.4616 - val_accuracy: 0.7692\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 362s 3s/step - loss: 0.3698 - accuracy: 0.8310 - val_loss: 0.4719 - val_accuracy: 0.7587\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 312s 3s/step - loss: 0.2910 - accuracy: 0.8723 - val_loss: 0.5218 - val_accuracy: 0.7624\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 362s 3s/step - loss: 0.2164 - accuracy: 0.9051 - val_loss: 0.6339 - val_accuracy: 0.7598\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 319s 3s/step - loss: 0.1547 - accuracy: 0.9344 - val_loss: 0.8235 - val_accuracy: 0.7499\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 336s 3s/step - loss: 0.1108 - accuracy: 0.9493 - val_loss: 0.9879 - val_accuracy: 0.7405\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 294s 2s/step - loss: 0.0834 - accuracy: 0.9588 - val_loss: 1.2578 - val_accuracy: 0.7504\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 308s 3s/step - loss: 0.0575 - accuracy: 0.9717 - val_loss: 1.5043 - val_accuracy: 0.7514\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 304s 3s/step - loss: 0.0485 - accuracy: 0.9768 - val_loss: 1.7094 - val_accuracy: 0.7457\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 293s 2s/step - loss: 0.0450 - accuracy: 0.9788 - val_loss: 1.7177 - val_accuracy: 0.7546\n",
      "=== MODEL EVALUATE TEST DATA ===\n",
      "\n",
      "Validation Accuracy: 0.7545596957206726\n",
      "Validation Loss: 1.7177084684371948\n",
      "\n",
      "13/60 [=====>........................] - ETA: 54s"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range (5):\n",
    "  result.append([i+1] + call())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def loss_func(df):\n",
    "  for idx, val in enumerate(df['No']):\n",
    "    plt.plot(df['Loss'].iloc[idx])\n",
    "    plt.plot(df['Val Loss'].iloc[idx])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.savefig(f'hasil/grafik/lossfunctionGraphics_BIGRU_CNN_UNIGRAM_BIGRAM_TRIGRAM_DROPOUT0.5-{idx+1}.png')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns=['No', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Loss', 'Val Loss'])\n",
    "df.to_csv('hasil/hasil_BIGRU_CNN_UNIGRAM_BIGRAM_TRIGRAM_DROPOUT0.5.csv', index=False)\n",
    "\n",
    "#average\n",
    "print('Average Accuracy :', df['Accuracy'].mean())\n",
    "print('Average Precision :', df['Precision'].mean())\n",
    "print('Average Recall :', df['Recall'].mean())\n",
    "print('Average F1 Score :', df['F1 Score'].mean())\n",
    "loss_func(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
