{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim library\n",
    "# memakai gensim karena sudah support FastText\n",
    "from gensim.models import FastText\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from numba import cuda\n",
    "\n",
    "# NLTK library\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Common packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE CONSTANT\n",
    "top_1_column = ['Rank 1']\n",
    "top_5_column = ['Rank 1', 'Rank 2', 'Rank 3', 'Rank 4', 'Rank 5']\n",
    "top_10_column = ['Rank 1', 'Rank 2', 'Rank 3', 'Rank 4', 'Rank 5', 'Rank 6', 'Rank 7', 'Rank 8', 'Rank 9', 'Rank 10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildFasttext:\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "\n",
    "    def build_fastText(self):\n",
    "        \"\"\"_summary_\n",
    "        Returns:\n",
    "            _model(bin)_: _model fasttext_\n",
    "        \"\"\"\n",
    "        print('====== BUILDING FASTTEXT MODEL IN PROCESS ! ======')\n",
    "        model = FastText(sentences=self.corpus['unigram-bigram'])  # instantiate\n",
    "        print('====== BUILDING FASTTEXT MODEL DONE ! ======')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_rank_column(self, df_sim, rank):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            df_sim (_array_): _list dari similarity_\n",
    "            rank (_int_): _rank yang dibutuhkan_\n",
    "\n",
    "        Returns:\n",
    "            _dataframe_: _data yang berisi kolum baru sesuai permintaan rank_\n",
    "        \"\"\"\n",
    "        match rank:\n",
    "            case 1:\n",
    "                for column in top_1_column:\n",
    "                    df_sim[column] = ''\n",
    "                return df_sim\n",
    "            case 5:\n",
    "                for column in top_5_column:\n",
    "                    df_sim[column] = ''\n",
    "                return df_sim\n",
    "            case 10:\n",
    "                for column in top_10_column:\n",
    "                    df_sim[column] = ''\n",
    "                return df_sim\n",
    "\n",
    "    def build_n_rank(self, df_sim_keys, model_input, rank):\n",
    "        \"\"\"_summary_\n",
    "        Args:\n",
    "            df_sim_keys (_array_): _list dari similarity_\n",
    "            model_input (_file(bin)_): _model fasttext yang disimpan_\n",
    "            rank (_int_): _definisi rank_\n",
    "        Returns:\n",
    "            _type_: _list dari rank words_\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_similarity = model_input.most_similar(df_sim_keys, topn=rank)\n",
    "            word = [data_similarity[i][0] for i in range(len(data_similarity))]\n",
    "            return word\n",
    "        except:\n",
    "            word = []\n",
    "            return word\n",
    "\n",
    "    def save_to_csv(self, df_sim, filename):\n",
    "        df_sim.to_csv(filename, index=False)\n",
    "        \n",
    "    def save_model(self, model, name):\n",
    "        model.wv.save(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_ngrams(dataset, n):\n",
    "    if n == 3:\n",
    "        dataset[f'unigram-bigram-trigram'] = ''\n",
    "        ngramtokendf = dataset[f'unigram-bigram-trigram']\n",
    "    if n == 2:\n",
    "        dataset[f'unigram-bigram'] = ''\n",
    "        ngramtokendf = dataset[f'unigram-bigram']\n",
    "    if n == 1:\n",
    "        dataset[f'unigram'] = ''\n",
    "        ngramtokendf = dataset[f'unigram']\n",
    "    indices_to_drop = []  # List to store indices of rows to be dropped\n",
    "\n",
    "    for idx, text in enumerate(dataset['preprocess_final']):\n",
    "        try:\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            ngrams_list = list(ngrams(tokens, n))\n",
    "            if n == 1:\n",
    "                ngrams_joined = [' '.join(gram) for gram in ngrams_list]\n",
    "            elif n == 2:\n",
    "                ngrams_joined = [' '.join(gram) for gram in ngrams_list]\n",
    "                unigrams = tokens\n",
    "                bigrams = [' '.join(gram) for gram in list(ngrams(tokens, 2))]\n",
    "                ngrams_joined = unigrams + bigrams\n",
    "            elif n == 3:\n",
    "                ngrams_joined = [' '.join(gram) for gram in ngrams_list]\n",
    "                unigrams = tokens\n",
    "                bigrams = [' '.join(gram) for gram in list(ngrams(tokens, 2))]\n",
    "                trigrams = [' '.join(gram) for gram in list(ngrams(tokens, 3))]\n",
    "                ngrams_joined = unigrams + bigrams + trigrams\n",
    "            else:\n",
    "                ngrams_joined = [' '.join(gram) for gram in ngrams_list]\n",
    "            ngramtokendf.iloc[idx] = ngrams_joined\n",
    "        except TypeError:\n",
    "                indices_to_drop = []  # List to store indices of rows to be dropped\n",
    "    dataset = dataset.drop(indices_to_drop)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BUILDING CORPUS BERITA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "corpus_berita = pd.read_csv('../data/data_preprocessed/corpus_fasttext/corpus_berita_clean_final.csv')\n",
    "corpus_berita = create_ngrams(corpus_berita, 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0         [wakil, gubernur, dki, djarot, syaiful, hidaya...\n1         [badan, awas, milu, dki, tunggu, lapor, anggap...\n2         [wakil, ketua, komisi, dpr, saleh, partaonan, ...\n3         [pasang, calon, nomor, urut, anies, baswedan, ...\n4         [rumah, partai, golkar, guncang, ujung, februa...\n                                ...                        \n140293    [tuhan, cipta, bangsa, maju, lawan, bohong, el...\n140294    [laku, impi, dalam, berani, jenius, kuat, ajai...\n140295    [juang, sejati, nilai, mula, bagamana, selesai...\n140296    [jatuh, ndash, benar, sikap, kartini, jatuh nd...\n140297    [suka, jujur, percaya, cinta, hormat, ali, bin...\nName: unigram-bigram, Length: 140298, dtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_berita['unigram-bigram']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== BUILDING FASTTEXT MODEL IN PROCESS ! ======\n",
      "====== BUILDING FASTTEXT MODEL DONE ! ======\n"
     ]
    }
   ],
   "source": [
    "constuctFastText = BuildFasttext(corpus_berita)\n",
    "models = constuctFastText.build_fastText()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "models_berita = models.wv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TESTING CORPUS BERITA FASTTEXT MODEL AND BUILD TOPN SPREADSHEET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[('lgbtq', 0.9788029193878174),\n ('lgbtiq', 0.9276920557022095),\n ('gay biseksual', 0.8281980752944946),\n ('lgbt lesbian', 0.819657564163208),\n ('lgv', 0.8174654841423035),\n ('biseksual', 0.8110087513923645),\n ('kaum lesbian', 0.8075315952301025),\n ('isu lesbian', 0.7828415036201477),\n ('kaum homoseksual', 0.7606260180473328),\n ('aseksual', 0.7514986395835876)]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing corpus load model\n",
    "models_berita.most_similar(\"lgbt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478665\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary as a set\n",
    "vocab = set(models_berita.key_to_index.keys())\n",
    "print(len(vocab))\n",
    "# Get the list of keys\n",
    "keys = models_berita.index_to_key\n",
    "# print(keys)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah kata : 478665\n",
      "data frame : (478665, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Words\n0      dalam\n1       laku\n2  indonesia",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(keys)\n",
    "df_similarity_berita = pd.DataFrame({'Words': words})\n",
    "print(f'jumlah kata : {len(df_similarity_berita)}')\n",
    "print(f'data frame : {df_similarity_berita.shape}')\n",
    "df_similarity_berita.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df similarity top10 : Index(['Words', 'Rank 1', 'Rank 2', 'Rank 3', 'Rank 4', 'Rank 5', 'Rank 6',\n",
      "       'Rank 7', 'Rank 8', 'Rank 9', 'Rank 10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# make copy of df_similarity\n",
    "df_similarity_berita_top10 = df_similarity_berita.copy()\n",
    "df_similarity_berita_top10 = constuctFastText.build_rank_column(df_similarity_berita_top10, 10)\n",
    "\n",
    "print(f'df similarity top10 : {df_similarity_berita_top10.columns}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "for j in range(len(df_similarity_berita_top10['Words'])):\n",
    "    word = constuctFastText.build_n_rank(df_similarity_berita_top10['Words'][j], models_berita, 10)\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 1'] = word[0]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 2'] = word[1]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 3'] = word[2]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 4'] = word[3]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 5'] = word[4]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 6'] = word[5]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 7'] = word[6]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 8'] = word[7]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 9'] = word[8]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 10'] = word[9]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#  save each data to dataset\n",
    "constuctFastText.save_to_csv(df_similarity_berita_top10,'../data/data_preprocessed/corpus_fasttext_topnrank/berita/df_similarity_top10_unigram_bigram.csv')\n",
    "\n",
    "print(f'done!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BUILDING CORPUS TWITTER-BERITA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "          topik            sumber  \\\n0       politik  cnnindonesia.com   \n1       politik  cnnindonesia.com   \n2       politik  cnnindonesia.com   \n3       politik  cnnindonesia.com   \n4       politik  cnnindonesia.com   \n...         ...               ...   \n190134      NaN               NaN   \n190135      NaN               NaN   \n190136      NaN               NaN   \n190137      NaN               NaN   \n190138      NaN               NaN   \n\n                                                      url  \\\n0       http://cnnindonesia.com/kursipanasdki1/2017030...   \n1       http://cnnindonesia.com/kursipanasdki1/2017030...   \n2       http://cnnindonesia.com/politik/20170301132408...   \n3       http://cnnindonesia.com/kursipanasdki1/2017030...   \n4       http://cnnindonesia.com/kursipanasdki1/2017022...   \n...                                                   ...   \n190134                                                NaN   \n190135                                                NaN   \n190136                                                NaN   \n190137                                                NaN   \n190138                                                NaN   \n\n                                                      isi  \\\n0        Jakarta, Wakil Gubernur DKI Jakarta Djarot Sy...   \n1        Jakarta, Badan Pengawas Pemilu DKI Jakarta me...   \n2        Jakarta, Wakil Ketua Komisi IX DPR, Saleh Par...   \n3        Jakarta, Pasangan calon nomor urut tiga, Anie...   \n4        Jakarta, Rumah Partai Golkar sedikit tergunca...   \n...                                                   ...   \n190134                                                NaN   \n190135                                                NaN   \n190136                                                NaN   \n190137                                                NaN   \n190138                                                NaN   \n\n                                         preprocess_clean  \\\n0       Jakarta Wakil Gubernur DKI Djarot Syaiful Hida...   \n1       Jakarta Badan Pengawas Pemilu DKI menunggu lap...   \n2       Jakarta Wakil Ketua Komisi DPR Saleh Partaonan...   \n3       Jakarta Pasangan calon nomor urut tiga Anies B...   \n4       Jakarta Rumah Partai Golkar sedikit terguncang...   \n...                                                   ...   \n190134                   gue tolol bgt kalo dipikir pikir   \n190135              Lagu ganyambung sama event euro tolol   \n190136  PADAHAL UDH NGETWEET GINI MULU TAPI GUE TETEP ...   \n190137               orang tolol megang pengorengan panas   \n190138                                         tolol wkwk   \n\n                                  preprocess_case_folding  \\\n0       jakarta wakil gubernur dki djarot syaiful hida...   \n1       jakarta badan pengawas pemilu dki menunggu lap...   \n2       jakarta wakil ketua komisi dpr saleh partaonan...   \n3       jakarta pasangan calon nomor urut tiga anies b...   \n4       jakarta rumah partai golkar sedikit terguncang...   \n...                                                   ...   \n190134                   gue tolol bgt kalo dipikir pikir   \n190135              lagu ganyambung sama event euro tolol   \n190136  padahal udh ngetweet gini mulu tapi gue tetep ...   \n190137               orang tolol megang pengorengan panas   \n190138                                         tolol wkwk   \n\n                                       preprocess_stemmer  \\\n0       jakarta wakil gubernur dki djarot syaiful hida...   \n1       jakarta badan awas milu dki tunggu lapor dari ...   \n2       jakarta wakil ketua komisi dpr saleh partaonan...   \n3       jakarta pasang calon nomor urut tiga anies bas...   \n4       jakarta rumah partai golkar sedikit guncang uj...   \n...                                                   ...   \n190134                     gue tolol bgt kalo pikir pikir   \n190135              lagu ganyambung sama event euro tolol   \n190136  padahal udh ngetweet gin mulu tapi gue tetep m...   \n190137                     orang tolol megang oreng panas   \n190138                                         tolol wkwk   \n\n                                 preprocess_normalization  \\\n0       jakarta wakil gubernur dki djarot syaiful hida...   \n1       jakarta badan awas milu dki tunggu lapor dari ...   \n2       jakarta wakil ketua komisi dpr saleh partaonan...   \n3       jakarta pasang calon nomor urut tiga anies bas...   \n4       jakarta rumah partai golkar sedikit guncang uj...   \n...                                                   ...   \n190134                saya tolol banget kalau pikir pikir   \n190135              lagu ganyambung sama event euro tolol   \n190136  padahal sudah ngetweet gin melulu tapi saya te...   \n190137                     orang tolol megang oreng panas   \n190138                                      tolol tertawa   \n\n                                         preprocess_token  \\\n0       ['wakil', 'gubernur', 'dki', 'djarot', 'syaifu...   \n1       ['badan', 'awas', 'milu', 'dki', 'tunggu', 'la...   \n2       ['wakil', 'ketua', 'komisi', 'dpr', 'saleh', '...   \n3       ['pasang', 'calon', 'nomor', 'urut', 'anies', ...   \n4       ['rumah', 'partai', 'golkar', 'guncang', 'ujun...   \n...                                                   ...   \n190134              ['tolol', 'banget', 'pikir', 'pikir']   \n190135   ['lagu', 'ganyambung', 'event', 'euro', 'tolol']   \n190136  ['ngetweet', 'gin', 'melulu', 'tetep', 'minum'...   \n190137              ['tolol', 'megang', 'oreng', 'panas']   \n190138                               ['tolol', 'tertawa']   \n\n                                         preprocess_final  \\\n0       wakil gubernur dki djarot syaiful hidayat ban ...   \n1       badan awas milu dki tunggu lapor anggap kartu ...   \n2       wakil ketua komisi dpr saleh partaonan dulay p...   \n3       pasang calon nomor urut anies baswedan sandiag...   \n4       rumah partai golkar guncang ujung februari pic...   \n...                                                   ...   \n190134                           tolol banget pikir pikir   \n190135                   lagu ganyambung event euro tolol   \n190136         ngetweet gin melulu tetep minum kopi tolol   \n190137                           tolol megang oreng panas   \n190138                                      tolol tertawa   \n\n                                                    tweet label_fase_1  \\\n0                                                     NaN          NaN   \n1                                                     NaN          NaN   \n2                                                     NaN          NaN   \n3                                                     NaN          NaN   \n4                                                     NaN          NaN   \n...                                                   ...          ...   \n190134                   gue tolol bgt kalo dipikir pikir           HS   \n190135  @TeamBTS14938305 @OmarKevin17 @Reel_good Lagu ...           HS   \n190136  PADAHAL UDH NGETWEET GINI MULU TAPI GUE TETEP ...           HS   \n190137      &lt;---- orang tolol megang pengorengan panas           HS   \n190138               tolol u wkwk https://t.co/VXsUzBQA6O           HS   \n\n       label_fase_2 label_fase_3 label_final  \\\n0               NaN          NaN         NaN   \n1               NaN          NaN         NaN   \n2               NaN          NaN         NaN   \n3               NaN          NaN         NaN   \n4               NaN          NaN         NaN   \n...             ...          ...         ...   \n190134           HS           HS          HS   \n190135           HS           HS          HS   \n190136           HS           HS          HS   \n190137           HS           HS          HS   \n190138           HS           HS          HS   \n\n                                           unigram-bigram  \n0       [wakil, gubernur, dki, djarot, syaiful, hidaya...  \n1       [badan, awas, milu, dki, tunggu, lapor, anggap...  \n2       [wakil, ketua, komisi, dpr, saleh, partaonan, ...  \n3       [pasang, calon, nomor, urut, anies, baswedan, ...  \n4       [rumah, partai, golkar, guncang, ujung, februa...  \n...                                                   ...  \n190134  [tolol, banget, pikir, pikir, tolol banget, ba...  \n190135  [lagu, ganyambung, event, euro, tolol, lagu ga...  \n190136  [ngetweet, gin, melulu, tetep, minum, kopi, to...  \n190137  [tolol, megang, oreng, panas, tolol megang, me...  \n190138                    [tolol, tertawa, tolol tertawa]  \n\n[190139 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topik</th>\n      <th>sumber</th>\n      <th>url</th>\n      <th>isi</th>\n      <th>preprocess_clean</th>\n      <th>preprocess_case_folding</th>\n      <th>preprocess_stemmer</th>\n      <th>preprocess_normalization</th>\n      <th>preprocess_token</th>\n      <th>preprocess_final</th>\n      <th>tweet</th>\n      <th>label_fase_1</th>\n      <th>label_fase_2</th>\n      <th>label_fase_3</th>\n      <th>label_final</th>\n      <th>unigram-bigram</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>politik</td>\n      <td>cnnindonesia.com</td>\n      <td>http://cnnindonesia.com/kursipanasdki1/2017030...</td>\n      <td>Jakarta, Wakil Gubernur DKI Jakarta Djarot Sy...</td>\n      <td>Jakarta Wakil Gubernur DKI Djarot Syaiful Hida...</td>\n      <td>jakarta wakil gubernur dki djarot syaiful hida...</td>\n      <td>jakarta wakil gubernur dki djarot syaiful hida...</td>\n      <td>jakarta wakil gubernur dki djarot syaiful hida...</td>\n      <td>['wakil', 'gubernur', 'dki', 'djarot', 'syaifu...</td>\n      <td>wakil gubernur dki djarot syaiful hidayat ban ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[wakil, gubernur, dki, djarot, syaiful, hidaya...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>politik</td>\n      <td>cnnindonesia.com</td>\n      <td>http://cnnindonesia.com/kursipanasdki1/2017030...</td>\n      <td>Jakarta, Badan Pengawas Pemilu DKI Jakarta me...</td>\n      <td>Jakarta Badan Pengawas Pemilu DKI menunggu lap...</td>\n      <td>jakarta badan pengawas pemilu dki menunggu lap...</td>\n      <td>jakarta badan awas milu dki tunggu lapor dari ...</td>\n      <td>jakarta badan awas milu dki tunggu lapor dari ...</td>\n      <td>['badan', 'awas', 'milu', 'dki', 'tunggu', 'la...</td>\n      <td>badan awas milu dki tunggu lapor anggap kartu ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[badan, awas, milu, dki, tunggu, lapor, anggap...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>politik</td>\n      <td>cnnindonesia.com</td>\n      <td>http://cnnindonesia.com/politik/20170301132408...</td>\n      <td>Jakarta, Wakil Ketua Komisi IX DPR, Saleh Par...</td>\n      <td>Jakarta Wakil Ketua Komisi DPR Saleh Partaonan...</td>\n      <td>jakarta wakil ketua komisi dpr saleh partaonan...</td>\n      <td>jakarta wakil ketua komisi dpr saleh partaonan...</td>\n      <td>jakarta wakil ketua komisi dpr saleh partaonan...</td>\n      <td>['wakil', 'ketua', 'komisi', 'dpr', 'saleh', '...</td>\n      <td>wakil ketua komisi dpr saleh partaonan dulay p...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[wakil, ketua, komisi, dpr, saleh, partaonan, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>politik</td>\n      <td>cnnindonesia.com</td>\n      <td>http://cnnindonesia.com/kursipanasdki1/2017030...</td>\n      <td>Jakarta, Pasangan calon nomor urut tiga, Anie...</td>\n      <td>Jakarta Pasangan calon nomor urut tiga Anies B...</td>\n      <td>jakarta pasangan calon nomor urut tiga anies b...</td>\n      <td>jakarta pasang calon nomor urut tiga anies bas...</td>\n      <td>jakarta pasang calon nomor urut tiga anies bas...</td>\n      <td>['pasang', 'calon', 'nomor', 'urut', 'anies', ...</td>\n      <td>pasang calon nomor urut anies baswedan sandiag...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[pasang, calon, nomor, urut, anies, baswedan, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>politik</td>\n      <td>cnnindonesia.com</td>\n      <td>http://cnnindonesia.com/kursipanasdki1/2017022...</td>\n      <td>Jakarta, Rumah Partai Golkar sedikit tergunca...</td>\n      <td>Jakarta Rumah Partai Golkar sedikit terguncang...</td>\n      <td>jakarta rumah partai golkar sedikit terguncang...</td>\n      <td>jakarta rumah partai golkar sedikit guncang uj...</td>\n      <td>jakarta rumah partai golkar sedikit guncang uj...</td>\n      <td>['rumah', 'partai', 'golkar', 'guncang', 'ujun...</td>\n      <td>rumah partai golkar guncang ujung februari pic...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[rumah, partai, golkar, guncang, ujung, februa...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>190134</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>gue tolol bgt kalo dipikir pikir</td>\n      <td>gue tolol bgt kalo dipikir pikir</td>\n      <td>gue tolol bgt kalo pikir pikir</td>\n      <td>saya tolol banget kalau pikir pikir</td>\n      <td>['tolol', 'banget', 'pikir', 'pikir']</td>\n      <td>tolol banget pikir pikir</td>\n      <td>gue tolol bgt kalo dipikir pikir</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>[tolol, banget, pikir, pikir, tolol banget, ba...</td>\n    </tr>\n    <tr>\n      <th>190135</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Lagu ganyambung sama event euro tolol</td>\n      <td>lagu ganyambung sama event euro tolol</td>\n      <td>lagu ganyambung sama event euro tolol</td>\n      <td>lagu ganyambung sama event euro tolol</td>\n      <td>['lagu', 'ganyambung', 'event', 'euro', 'tolol']</td>\n      <td>lagu ganyambung event euro tolol</td>\n      <td>@TeamBTS14938305 @OmarKevin17 @Reel_good Lagu ...</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>[lagu, ganyambung, event, euro, tolol, lagu ga...</td>\n    </tr>\n    <tr>\n      <th>190136</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>PADAHAL UDH NGETWEET GINI MULU TAPI GUE TETEP ...</td>\n      <td>padahal udh ngetweet gini mulu tapi gue tetep ...</td>\n      <td>padahal udh ngetweet gin mulu tapi gue tetep m...</td>\n      <td>padahal sudah ngetweet gin melulu tapi saya te...</td>\n      <td>['ngetweet', 'gin', 'melulu', 'tetep', 'minum'...</td>\n      <td>ngetweet gin melulu tetep minum kopi tolol</td>\n      <td>PADAHAL UDH NGETWEET GINI MULU TAPI GUE TETEP ...</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>[ngetweet, gin, melulu, tetep, minum, kopi, to...</td>\n    </tr>\n    <tr>\n      <th>190137</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>orang tolol megang pengorengan panas</td>\n      <td>orang tolol megang pengorengan panas</td>\n      <td>orang tolol megang oreng panas</td>\n      <td>orang tolol megang oreng panas</td>\n      <td>['tolol', 'megang', 'oreng', 'panas']</td>\n      <td>tolol megang oreng panas</td>\n      <td>&amp;lt;---- orang tolol megang pengorengan panas</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>[tolol, megang, oreng, panas, tolol megang, me...</td>\n    </tr>\n    <tr>\n      <th>190138</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>tolol wkwk</td>\n      <td>tolol wkwk</td>\n      <td>tolol wkwk</td>\n      <td>tolol tertawa</td>\n      <td>['tolol', 'tertawa']</td>\n      <td>tolol tertawa</td>\n      <td>tolol u wkwk https://t.co/VXsUzBQA6O</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>HS</td>\n      <td>[tolol, tertawa, tolol tertawa]</td>\n    </tr>\n  </tbody>\n</table>\n<p>190139 rows Ã— 16 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_berita = pd.read_csv('../data/data_preprocessed/corpus_fasttext/corpus_berita_clean_final.csv')\n",
    "corpus_twitter = pd.read_csv('../data/data_preprocessed/dataset/DatasetHateSpeech_Final_TA2023.csv')\n",
    "\n",
    "corpus_tweetberita = pd.concat([corpus_berita, corpus_twitter], ignore_index=True)\n",
    "# read csv\n",
    "create_ngrams(corpus_tweetberita, 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== BUILDING FASTTEXT MODEL IN PROCESS ! ======\n",
      "====== BUILDING FASTTEXT MODEL DONE ! ======\n"
     ]
    }
   ],
   "source": [
    "constuctFastText = BuildFasttext(corpus_tweetberita)\n",
    "model = constuctFastText.build_fastText()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model_tweetberita = model.wv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TESTING CORPUS TWEETBERITA FASTTEXT MODEL AND BUILD TOPN SPREADSHEET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[('mitos tidur', 0.8141387104988098),\n ('tidur istirahat', 0.8001329302787781),\n ('tidur tidur', 0.7955479621887207),\n ('tidk', 0.7874872088432312),\n ('capek tidur', 0.7735072374343872),\n ('mimpi tidur', 0.7689397931098938),\n ('istirahat', 0.7585166096687317),\n ('tid', 0.7552476525306702),\n ('tidur nyenyak', 0.7464496493339539),\n ('thinkstock tidur', 0.7463703155517578)]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tweetberita.most_similar(\"tidur\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494160\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary as a set\n",
    "vocab = set(model_tweetberita.key_to_index.keys())\n",
    "print(len(vocab))\n",
    "# Get the list of keys\n",
    "keys = model_tweetberita.index_to_key\n",
    "# print(keys)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah kata : 494160\n",
      "data frame : (494160, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Words\n0      dalam\n1       laku\n2  indonesia",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(keys)\n",
    "df_similarity_tweetberita = pd.DataFrame({'Words': words})\n",
    "print(f'jumlah kata : {len(df_similarity_tweetberita)}')\n",
    "print(f'data frame : {df_similarity_tweetberita.shape}')\n",
    "df_similarity_tweetberita.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df similarity top10 : Index(['Words', 'Rank 1', 'Rank 2', 'Rank 3', 'Rank 4', 'Rank 5', 'Rank 6',\n",
      "       'Rank 7', 'Rank 8', 'Rank 9', 'Rank 10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_similarity_tweetberita_top10 = df_similarity_tweetberita.copy()\n",
    "df_similarity_tweetberita_top10 = constuctFastText.build_rank_column(df_similarity_tweetberita_top10, 10)\n",
    "\n",
    "# test\n",
    "print(f'df similarity top10 : {df_similarity_tweetberita_top10.columns}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "       Words Rank 1 Rank 2 Rank 3 Rank 4 Rank 5 Rank 6 Rank 7 Rank 8 Rank 9  \\\n0      dalam                                                                  \n1       laku                                                                  \n2  indonesia                                                                  \n\n  Rank 10  \n0          \n1          \n2          ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Rank 1</th>\n      <th>Rank 2</th>\n      <th>Rank 3</th>\n      <th>Rank 4</th>\n      <th>Rank 5</th>\n      <th>Rank 6</th>\n      <th>Rank 7</th>\n      <th>Rank 8</th>\n      <th>Rank 9</th>\n      <th>Rank 10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similarity_tweetberita_top10.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "for j in range(len(df_similarity_tweetberita_top10['Words'])):\n",
    "    word = constuctFastText.build_n_rank(df_similarity_tweetberita_top10['Words'][j], model_tweetberita, 10)\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 1'] = word[0]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 2'] = word[1]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 3'] = word[2]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 4'] = word[3]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 5'] = word[4]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 6'] = word[5]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 7'] = word[6]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 8'] = word[7]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 9'] = word[8]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 10'] = word[9]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "       Words      Rank 1        Rank 2      Rank 3      Rank 4      Rank 5  \\\n0      dalam   pengalamn     tadalafil     adalagi       afdal       adala   \n1       laku  melakukkan    imelakukan  melakukaan  dillakukan    dilakuin   \n2  indonesia    indonesi  indonesianis  indonesian  indonesien  indonesias   \n\n      Rank 6          Rank 7     Rank 8     Rank 9          Rank 10  \n0   amygdala           amdal      tidal       adal      kadaluwarsa  \n1  dilakulan      dilakuakan   mlakukan  melakulan       melakuakan  \n2   indoneia  indonesianisme  indoneaia  indonesie  indonesiancloud  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Rank 1</th>\n      <th>Rank 2</th>\n      <th>Rank 3</th>\n      <th>Rank 4</th>\n      <th>Rank 5</th>\n      <th>Rank 6</th>\n      <th>Rank 7</th>\n      <th>Rank 8</th>\n      <th>Rank 9</th>\n      <th>Rank 10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n      <td>pengalamn</td>\n      <td>tadalafil</td>\n      <td>adalagi</td>\n      <td>afdal</td>\n      <td>adala</td>\n      <td>amygdala</td>\n      <td>amdal</td>\n      <td>tidal</td>\n      <td>adal</td>\n      <td>kadaluwarsa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n      <td>melakukkan</td>\n      <td>imelakukan</td>\n      <td>melakukaan</td>\n      <td>dillakukan</td>\n      <td>dilakuin</td>\n      <td>dilakulan</td>\n      <td>dilakuakan</td>\n      <td>mlakukan</td>\n      <td>melakulan</td>\n      <td>melakuakan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n      <td>indonesi</td>\n      <td>indonesianis</td>\n      <td>indonesian</td>\n      <td>indonesien</td>\n      <td>indonesias</td>\n      <td>indoneia</td>\n      <td>indonesianisme</td>\n      <td>indoneaia</td>\n      <td>indonesie</td>\n      <td>indonesiancloud</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similarity_tweetberita_top10.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "constuctFastText.save_to_csv(df_similarity_tweetberita_top10, '../data/data_preprocessed/corpus_fasttext_topnrank/tweet_berita/df_similartiy_top10_unigram_bigram.csv')\n",
    "print(f'done!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BUILDING CORPUS TWEET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0         [wakil, gubernur, dki, djarot, syaiful, hidaya...\n1         [badan, awas, milu, dki, tunggu, lapor, anggap...\n2         [wakil, ketua, komisi, dpr, saleh, partaonan, ...\n3         [pasang, calon, nomor, urut, anies, baswedan, ...\n4         [rumah, partai, golkar, guncang, ujung, februa...\n                                ...                        \n140293    [tuhan, cipta, bangsa, maju, lawan, bohong, el...\n140294    [laku, impi, dalam, berani, jenius, kuat, ajai...\n140295    [juang, sejati, nilai, mula, bagamana, selesai...\n140296    [jatuh, ndash, benar, sikap, kartini, jatuh nd...\n140297    [suka, jujur, percaya, cinta, hormat, ali, bin...\nName: unigram-bigram, Length: 140298, dtype: object"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_twitter = pd.read_csv('../data/data_preprocessed/dataset/DatasetHateSpeech_Final_TA2023.csv')\n",
    "corpus_twitter = create_ngrams(corpus_berita, 2)\n",
    "corpus_twitter['unigram-bigram']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== BUILDING FASTTEXT MODEL IN PROCESS ! ======\n",
      "====== BUILDING FASTTEXT MODEL DONE ! ======\n"
     ]
    }
   ],
   "source": [
    "constuctFastText = BuildFasttext(corpus_twitter)\n",
    "model = constuctFastText.build_fastText()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model_tweet = model.wv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[('ortopedi', 0.7949845790863037),\n ('hipertensi', 0.7728633880615234),\n ('kardiologi', 0.7554982304573059),\n ('fisiologi', 0.7548489570617676),\n ('indepedensi', 0.7518232464790344),\n ('forensik', 0.7473798990249634),\n ('efesiensi', 0.7465602159500122),\n ('prolog', 0.745785117149353),\n ('audiensi', 0.7455964088439941),\n ('hedi', 0.7445394396781921)]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tweet.most_similar(\"ensiklopedi\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478665\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary as a set\n",
    "vocab = set(model_tweet.key_to_index.keys())\n",
    "print(len(vocab))\n",
    "# Get the list of keys\n",
    "keys = model_tweet.index_to_key\n",
    "# print(keys)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah kata : 478665\n",
      "data frame : (478665, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Words\n0      dalam\n1       laku\n2  indonesia",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(keys)\n",
    "df_similarity_tweet = pd.DataFrame({'Words': words})\n",
    "print(f'jumlah kata : {len(df_similarity_tweet)}')\n",
    "print(f'data frame : {df_similarity_tweet.shape}')\n",
    "df_similarity_tweet.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df_similarity_tweettop10 = df_similarity_tweet.copy()\n",
    "df_similarity_tweettop10 = constuctFastText.build_rank_column(df_similarity_tweettop10, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df similarity top10 : Index(['Words', 'Rank 1', 'Rank 2', 'Rank 3', 'Rank 4', 'Rank 5', 'Rank 6',\n",
      "       'Rank 7', 'Rank 8', 'Rank 9', 'Rank 10'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Words Rank 1 Rank 2 Rank 3 Rank 4 Rank 5 Rank 6 Rank 7 Rank 8 Rank 9  \\\n0      dalam                                                                  \n1       laku                                                                  \n2  indonesia                                                                  \n\n  Rank 10  \n0          \n1          \n2          ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Rank 1</th>\n      <th>Rank 2</th>\n      <th>Rank 3</th>\n      <th>Rank 4</th>\n      <th>Rank 5</th>\n      <th>Rank 6</th>\n      <th>Rank 7</th>\n      <th>Rank 8</th>\n      <th>Rank 9</th>\n      <th>Rank 10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'df similarity top10 : {df_similarity_tweettop10.columns}')\n",
    "df_similarity_tweettop10.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for j in range(len(df_similarity_tweettop10['Words'])):\n",
    "    word = constuctFastText.build_n_rank(df_similarity_tweettop10['Words'][j], model_tweet, 10)\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 1'] = word[0]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 2'] = word[1]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 3'] = word[2]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 4'] = word[3]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 5'] = word[4]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 6'] = word[5]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 7'] = word[6]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 8'] = word[7]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 9'] = word[8]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 10'] = word[9]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_similarity_tweettop10.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "constuctFastText.save_to_csv(df_similarity_tweettop10, '../data/data_preprocessed/corpus_fasttext_topnrank/tweet/df_similartiy_top10_unigram_bigram.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(\"a\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71492d14f740f603cc1a98f45d005780e211da089f2b4c6f0de7b5842d0d8d70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
