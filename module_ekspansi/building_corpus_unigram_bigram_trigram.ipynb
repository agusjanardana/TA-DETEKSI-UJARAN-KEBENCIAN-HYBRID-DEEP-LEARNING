{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim library\n",
    "# memakai gensim karena sudah support FastText\n",
    "from gensim.models import FastText\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from numba import cuda\n",
    "\n",
    "# NLTK library\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Common packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE CONSTANT\n",
    "top_1_column = ['Rank 1']\n",
    "top_5_column = ['Rank 1', 'Rank 2', 'Rank 3', 'Rank 4', 'Rank 5']\n",
    "top_10_column = ['Rank 1', 'Rank 2', 'Rank 3', 'Rank 4', 'Rank 5', 'Rank 6', 'Rank 7', 'Rank 8', 'Rank 9', 'Rank 10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildFasttext:\n",
    "    def __init__(self, corpus, column):\n",
    "        self.corpus = corpus\n",
    "        self.column = column\n",
    "\n",
    "    def build_fastText(self):\n",
    "        \"\"\"_summary_\n",
    "        Returns:\n",
    "            _model(bin)_: _model fasttext_\n",
    "        \"\"\"\n",
    "        print('====== BUILDING FASTTEXT MODEL IN PROCESS ! ======')\n",
    "        model = FastText(sentences=self.corpus[self.column])  # instantiate\n",
    "        print('====== BUILDING FASTTEXT MODEL DONE ! ======')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_rank_column(self, df_sim, rank):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            df_sim (_array_): _list dari similarity_\n",
    "            rank (_int_): _rank yang dibutuhkan_\n",
    "\n",
    "        Returns:\n",
    "            _dataframe_: _data yang berisi kolum baru sesuai permintaan rank_\n",
    "        \"\"\"\n",
    "        if rank == 1:\n",
    "            for column in top_1_column:\n",
    "                    df_sim[column] = ''\n",
    "            return df_sim\n",
    "        \n",
    "        elif rank == 5:\n",
    "            for column in top_5_column:\n",
    "                    df_sim[column] = ''\n",
    "            return df_sim\n",
    "        \n",
    "        elif rank == 10:\n",
    "            for column in top_10_column:\n",
    "                    df_sim[column] = ''\n",
    "            return df_sim\n",
    "\n",
    "    def build_n_rank(self, df_sim_keys, model_input, rank):\n",
    "        \"\"\"_summary_\n",
    "        Args:\n",
    "            df_sim_keys (_array_): _list dari similarity_\n",
    "            model_input (_file(bin)_): _model fasttext yang disimpan_\n",
    "            rank (_int_): _definisi rank_\n",
    "        Returns:\n",
    "            _type_: _list dari rank words_\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_similarity = model_input.most_similar(df_sim_keys, topn=rank)\n",
    "            word = [data_similarity[i][0] for i in range(len(data_similarity))]\n",
    "            return word\n",
    "        except:\n",
    "            word = []\n",
    "            return word\n",
    "\n",
    "    def save_to_csv(self, df_sim, filename):\n",
    "        df_sim.to_csv(filename, index=False)\n",
    "        \n",
    "    def save_model(self, model, name):\n",
    "        model.wv.save(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_ngrams(dataset, n):\n",
    "    if n == 3:\n",
    "        dataset[f'unigram-bigram-trigram'] = ''\n",
    "        ngramtokendf = dataset[f'unigram-bigram-trigram']\n",
    "    if n == 2:\n",
    "        dataset[f'unigram-bigram'] = ''\n",
    "        ngramtokendf = dataset[f'unigram-bigram']\n",
    "    if n == 1:\n",
    "        dataset[f'unigram'] = ''\n",
    "        ngramtokendf = dataset[f'unigram']\n",
    "    indices_to_drop = []  # List to store indices of rows to be dropped\n",
    "\n",
    "    for idx, text in enumerate(dataset['preprocess_final']):\n",
    "        try:\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            ngrams_list = list(ngrams(tokens, n))\n",
    "            if n == 1:\n",
    "                ngrams_joined = [' '.join(gram) for gram in ngrams_list]\n",
    "            elif n == 2:\n",
    "                ngrams_joined = [' '.join(gram) for gram in ngrams_list]\n",
    "                unigrams = tokens\n",
    "                bigrams = [' '.join(gram) for gram in list(ngrams(tokens, 2))]\n",
    "                ngrams_joined = unigrams + bigrams\n",
    "            elif n == 3:\n",
    "                ngrams_joined = [' '.join(gram) for gram in ngrams_list]\n",
    "                unigrams = tokens\n",
    "                bigrams = [' '.join(gram) for gram in list(ngrams(tokens, 2))]\n",
    "                trigrams = [' '.join(gram) for gram in list(ngrams(tokens, 3))]\n",
    "                ngrams_joined = unigrams + bigrams + trigrams\n",
    "            else:\n",
    "                ngrams_joined = [' '.join(gram) for gram in ngrams_list]\n",
    "            ngramtokendf.iloc[idx] = ngrams_joined\n",
    "        except TypeError:\n",
    "                indices_to_drop = []  # List to store indices of rows to be dropped\n",
    "    dataset = dataset.drop(indices_to_drop)\n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## BUILDING CORPUS BERITA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_berita = pd.read_csv('../data/data_preprocessed/corpus_fasttext/corpus_berita_clean_final.csv')\n",
    "corpus_berita = create_ngrams(corpus_berita, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== BUILDING FASTTEXT MODEL IN PROCESS ! ======\n",
      "====== BUILDING FASTTEXT MODEL DONE ! ======\n"
     ]
    }
   ],
   "source": [
    "constuctFastText = BuildFasttext(corpus_berita, 'unigram-bigram-trigram')\n",
    "models = constuctFastText.build_fastText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_berita = models.wv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### TESTING CORPUS BERITA FASTTEXT MODEL AND BUILD TOPN SPREADSHEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('lgbtq', 0.9830506443977356),\n ('lgbtiq', 0.9227940440177917),\n ('gay biseksual', 0.848452627658844),\n ('biseksual', 0.832297682762146),\n ('lesbi gay biseksual', 0.8255335092544556),\n ('lgbt lesbian', 0.8174042701721191),\n ('lgv', 0.8102040886878967),\n ('gay biseks', 0.7882265448570251),\n ('kaum homoseksual', 0.7808271050453186),\n ('kaum lesbian', 0.7790321111679077)]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing corpus load model\n",
    "models_berita.most_similar(\"lgbt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617766\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary as a set\n",
    "vocab = set(models_berita.key_to_index.keys())\n",
    "print(len(vocab))\n",
    "# Get the list of keys\n",
    "keys = models_berita.index_to_key\n",
    "# print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah kata : 617766\n",
      "data frame : (617766, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Words\n0      dalam\n1       laku\n2  indonesia",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(keys)\n",
    "df_similarity_berita = pd.DataFrame({'Words': words})\n",
    "print(f'jumlah kata : {len(df_similarity_berita)}')\n",
    "print(f'data frame : {df_similarity_berita.shape}')\n",
    "df_similarity_berita.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df similarity top10 : Index(['Words', 'Rank 1', 'Rank 2', 'Rank 3', 'Rank 4', 'Rank 5', 'Rank 6',\n",
      "       'Rank 7', 'Rank 8', 'Rank 9', 'Rank 10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# make copy of df_similarity\n",
    "df_similarity_berita_top10 = df_similarity_berita.copy()\n",
    "df_similarity_berita_top10 = constuctFastText.build_rank_column(df_similarity_berita_top10, 10)\n",
    "\n",
    "print(f'df similarity top10 : {df_similarity_berita_top10.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(len(df_similarity_berita_top10['Words'])):\n",
    "    word = constuctFastText.build_n_rank(df_similarity_berita_top10['Words'][j], models_berita, 10)\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 1'] = word[0]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 2'] = word[1]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 3'] = word[2]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 4'] = word[3]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 5'] = word[4]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 6'] = word[5]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 7'] = word[6]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 8'] = word[7]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 9'] = word[8]\n",
    "    df_similarity_berita_top10.loc[j, 'Rank 10'] = word[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#  save each data to dataset\n",
    "constuctFastText.save_to_csv(df_similarity_berita_top10,'../data/data_preprocessed/corpus_fasttext_topnrank/berita/df_similarity_top10_unigram_bigram_trigram.csv')\n",
    "\n",
    "print(f'done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## BUILDING CORPUS TWITTER-BERITA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_berita = pd.read_csv('../data/data_preprocessed/corpus_fasttext/corpus_berita_clean_final.csv')\n",
    "corpus_twitter = pd.read_csv('../data/data_preprocessed/dataset/DatasetHateSpeech_Final_TA2023.csv')\n",
    "\n",
    "corpus_tweetberita = pd.concat([corpus_berita, corpus_twitter], ignore_index=True)\n",
    "# read csv\n",
    "corpus_tweetberita = create_ngrams(corpus_tweetberita, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== BUILDING FASTTEXT MODEL IN PROCESS ! ======\n",
      "====== BUILDING FASTTEXT MODEL DONE ! ======\n"
     ]
    }
   ],
   "source": [
    "constuctFastText = BuildFasttext(corpus_tweetberita, 'unigram-bigram-trigram')\n",
    "model = constuctFastText.build_fastText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_tweetberita = model.wv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### TESTING CORPUS TWEETBERITA FASTTEXT MODEL AND BUILD TOPN SPREADSHEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('tidur tidur', 0.811089813709259),\n ('mitos tidur', 0.8039990067481995),\n ('mimpi tidur', 0.7906509637832642),\n ('capek tidur', 0.7803537845611572),\n ('dur', 0.7792797684669495),\n ('tidk', 0.7790694236755371),\n ('tidur lelah', 0.7751440405845642),\n ('tidur istirahat', 0.773717999458313),\n ('thinkstock tidur', 0.7692169547080994),\n ('tid', 0.7564488649368286)]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tweetberita.most_similar(\"tidur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635336\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary as a set\n",
    "vocab = set(model_tweetberita.key_to_index.keys())\n",
    "print(len(vocab))\n",
    "# Get the list of keys\n",
    "keys = model_tweetberita.index_to_key\n",
    "# print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah kata : 635336\n",
      "data frame : (635336, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Words\n0      dalam\n1       laku\n2  indonesia",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(keys)\n",
    "df_similarity_tweetberita = pd.DataFrame({'Words': words})\n",
    "print(f'jumlah kata : {len(df_similarity_tweetberita)}')\n",
    "print(f'data frame : {df_similarity_tweetberita.shape}')\n",
    "df_similarity_tweetberita.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df similarity top10 : Index(['Words', 'Rank 1', 'Rank 2', 'Rank 3', 'Rank 4', 'Rank 5', 'Rank 6',\n",
      "       'Rank 7', 'Rank 8', 'Rank 9', 'Rank 10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_similarity_tweetberita_top10 = df_similarity_tweetberita.copy()\n",
    "df_similarity_tweetberita_top10 = constuctFastText.build_rank_column(df_similarity_tweetberita_top10, 10)\n",
    "\n",
    "# test\n",
    "print(f'df similarity top10 : {df_similarity_tweetberita_top10.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Words Rank 1 Rank 2 Rank 3 Rank 4 Rank 5 Rank 6 Rank 7 Rank 8 Rank 9  \\\n0      dalam                                                                  \n1       laku                                                                  \n2  indonesia                                                                  \n\n  Rank 10  \n0          \n1          \n2          ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Rank 1</th>\n      <th>Rank 2</th>\n      <th>Rank 3</th>\n      <th>Rank 4</th>\n      <th>Rank 5</th>\n      <th>Rank 6</th>\n      <th>Rank 7</th>\n      <th>Rank 8</th>\n      <th>Rank 9</th>\n      <th>Rank 10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similarity_tweetberita_top10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(len(df_similarity_tweetberita_top10['Words'])):\n",
    "    word = constuctFastText.build_n_rank(df_similarity_tweetberita_top10['Words'][j], model_tweetberita, 10)\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 1'] = word[0]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 2'] = word[1]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 3'] = word[2]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 4'] = word[3]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 5'] = word[4]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 6'] = word[5]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 7'] = word[6]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 8'] = word[7]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 9'] = word[8]\n",
    "    df_similarity_tweetberita_top10.loc[j, 'Rank 10'] = word[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Words        Rank 1      Rank 2      Rank 3          Rank 4  \\\n0      dalam     tadalafil   pengalamn     adalagi           adala   \n1       laku    melakukkan  melakukaan  imelakukan      dillakukan   \n2  indonesia  indonesianis    indonesi  indonesian  indonesianisme   \n\n       Rank 5      Rank 6         Rank 7           Rank 8            Rank 9  \\\n0    amygdala         psi        kognisi             apsi             kspsi   \n1    dilakuin   melakulan     melakuakan         melakuka         dilakulan   \n2  indonesias  indonesien  nesoindonesia  indonesiancloud  indonesiabermutu   \n\n      Rank 10  \n0         vsi  \n1  kelakuanya  \n2    indoneia  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Rank 1</th>\n      <th>Rank 2</th>\n      <th>Rank 3</th>\n      <th>Rank 4</th>\n      <th>Rank 5</th>\n      <th>Rank 6</th>\n      <th>Rank 7</th>\n      <th>Rank 8</th>\n      <th>Rank 9</th>\n      <th>Rank 10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n      <td>tadalafil</td>\n      <td>pengalamn</td>\n      <td>adalagi</td>\n      <td>adala</td>\n      <td>amygdala</td>\n      <td>psi</td>\n      <td>kognisi</td>\n      <td>apsi</td>\n      <td>kspsi</td>\n      <td>vsi</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n      <td>melakukkan</td>\n      <td>melakukaan</td>\n      <td>imelakukan</td>\n      <td>dillakukan</td>\n      <td>dilakuin</td>\n      <td>melakulan</td>\n      <td>melakuakan</td>\n      <td>melakuka</td>\n      <td>dilakulan</td>\n      <td>kelakuanya</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n      <td>indonesianis</td>\n      <td>indonesi</td>\n      <td>indonesian</td>\n      <td>indonesianisme</td>\n      <td>indonesias</td>\n      <td>indonesien</td>\n      <td>nesoindonesia</td>\n      <td>indonesiancloud</td>\n      <td>indonesiabermutu</td>\n      <td>indoneia</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similarity_tweetberita_top10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "constuctFastText.save_to_csv(df_similarity_tweetberita_top10, '../data/data_preprocessed/corpus_fasttext_topnrank/tweet_berita/df_similartiy_top10_unigram_bigram_trigram.csv')\n",
    "print(f'done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## BUILDING CORPUS TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_twitter = pd.read_csv('../data/data_preprocessed/dataset/DatasetHateSpeech_Final_TA2023.csv')\n",
    "corpus_twitter = create_ngrams(corpus_berita, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== BUILDING FASTTEXT MODEL IN PROCESS ! ======\n",
      "====== BUILDING FASTTEXT MODEL DONE ! ======\n"
     ]
    }
   ],
   "source": [
    "constuctFastText = BuildFasttext(corpus_twitter, 'unigram-bigram-trigram')\n",
    "model = constuctFastText.build_fastText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_tweet = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('ortopedi', 0.7615773677825928),\n ('hipertensi', 0.7476847767829895),\n ('defensif', 0.7394968271255493),\n ('suspensi', 0.737450897693634),\n ('forensik', 0.7295366525650024),\n ('subspesialis', 0.7289777398109436),\n ('ofensif', 0.728118896484375),\n ('efesien', 0.7235876321792603),\n ('efesiensi', 0.7227770090103149),\n ('ensiklopedia', 0.7211304306983948)]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tweet.most_similar(\"ensiklopedi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617766\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary as a set\n",
    "vocab = set(model_tweet.key_to_index.keys())\n",
    "print(len(vocab))\n",
    "# Get the list of keys\n",
    "keys = model_tweet.index_to_key\n",
    "# print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah kata : 617766\n",
      "data frame : (617766, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Words\n0      dalam\n1       laku\n2  indonesia",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(keys)\n",
    "df_similarity_tweet = pd.DataFrame({'Words': words})\n",
    "print(f'jumlah kata : {len(df_similarity_tweet)}')\n",
    "print(f'data frame : {df_similarity_tweet.shape}')\n",
    "df_similarity_tweet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_similarity_tweettop10 = df_similarity_tweet.copy()\n",
    "df_similarity_tweettop10 = constuctFastText.build_rank_column(df_similarity_tweettop10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df similarity top10 : Index(['Words', 'Rank 1', 'Rank 2', 'Rank 3', 'Rank 4', 'Rank 5', 'Rank 6',\n",
      "       'Rank 7', 'Rank 8', 'Rank 9', 'Rank 10'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Words Rank 1 Rank 2 Rank 3 Rank 4 Rank 5 Rank 6 Rank 7 Rank 8 Rank 9  \\\n0      dalam                                                                  \n1       laku                                                                  \n2  indonesia                                                                  \n\n  Rank 10  \n0          \n1          \n2          ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Rank 1</th>\n      <th>Rank 2</th>\n      <th>Rank 3</th>\n      <th>Rank 4</th>\n      <th>Rank 5</th>\n      <th>Rank 6</th>\n      <th>Rank 7</th>\n      <th>Rank 8</th>\n      <th>Rank 9</th>\n      <th>Rank 10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'df similarity top10 : {df_similarity_tweettop10.columns}')\n",
    "df_similarity_tweettop10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(len(df_similarity_tweettop10['Words'])):\n",
    "    word = constuctFastText.build_n_rank(df_similarity_tweettop10['Words'][j], model_tweet, 10)\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 1'] = word[0]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 2'] = word[1]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 3'] = word[2]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 4'] = word[3]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 5'] = word[4]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 6'] = word[5]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 7'] = word[6]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 8'] = word[7]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 9'] = word[8]\n",
    "    df_similarity_tweettop10.loc[j, 'Rank 10'] = word[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Words        Rank 1      Rank 2      Rank 3      Rank 4      Rank 5  \\\n0      dalam      amygdala   tadalafil       adala       afdal       amdal   \n1       laku    melakukkan  melakukaan  dillakukan  imelakukan    dilakuka   \n2  indonesia  indonesianis    indonesi  indonesian  indonesien  indonesias   \n\n           Rank 6         Rank 7           Rank 8      Rank 9  \\\n0           tidal        andalas             apsi         sil   \n1      dilakuakan      dilakulan         melakuka  melakuakan   \n2  indonesianisme  nesoindonesia  indonesiancloud    indoneia   \n\n            Rank 10  \n0           adalagi  \n1         melakuakn  \n2  indonesiabermutu  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Rank 1</th>\n      <th>Rank 2</th>\n      <th>Rank 3</th>\n      <th>Rank 4</th>\n      <th>Rank 5</th>\n      <th>Rank 6</th>\n      <th>Rank 7</th>\n      <th>Rank 8</th>\n      <th>Rank 9</th>\n      <th>Rank 10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dalam</td>\n      <td>amygdala</td>\n      <td>tadalafil</td>\n      <td>adala</td>\n      <td>afdal</td>\n      <td>amdal</td>\n      <td>tidal</td>\n      <td>andalas</td>\n      <td>apsi</td>\n      <td>sil</td>\n      <td>adalagi</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laku</td>\n      <td>melakukkan</td>\n      <td>melakukaan</td>\n      <td>dillakukan</td>\n      <td>imelakukan</td>\n      <td>dilakuka</td>\n      <td>dilakuakan</td>\n      <td>dilakulan</td>\n      <td>melakuka</td>\n      <td>melakuakan</td>\n      <td>melakuakn</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>indonesia</td>\n      <td>indonesianis</td>\n      <td>indonesi</td>\n      <td>indonesian</td>\n      <td>indonesien</td>\n      <td>indonesias</td>\n      <td>indonesianisme</td>\n      <td>nesoindonesia</td>\n      <td>indonesiancloud</td>\n      <td>indoneia</td>\n      <td>indonesiabermutu</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similarity_tweettop10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "constuctFastText.save_to_csv(df_similarity_tweettop10, '../data/data_preprocessed/corpus_fasttext_topnrank/tweet/df_similartiy_top10_unigram_bigram_trigram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71492d14f740f603cc1a98f45d005780e211da089f2b4c6f0de7b5842d0d8d70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
