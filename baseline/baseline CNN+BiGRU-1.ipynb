{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T14:21:22.572481010Z",
     "start_time": "2023-05-19T14:21:07.336248181Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, Bidirectional, AveragePooling1D, LSTM, GRU, Conv1D, MaxPooling1D, Flatten, GlobalMaxPooling1D, CuDNNGRU , GlobalAveragePooling1D, Concatenate, TimeDistributed\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T14:21:25.486891236Z",
     "start_time": "2023-05-19T14:21:22.575837984Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'compute_capability': (7, 0), 'device_name': 'Tesla V100-SXM2-16GB'}\n",
      "Found PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') GPU(s)\n",
      "Memory growth set to True, using Nvidia Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan informasi perangkat GPU yang digunakan\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    device_details = tf.config.experimental.get_device_details(device)\n",
    "    print(device_details)\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "try:\n",
    "    print(f'Found {physical_devices[0]} GPU(s)')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    assert tf.config.experimental.get_memory_growth(physical_devices[0])\n",
    "    print('Memory growth set to True, using Nvidia Tesla T4')\n",
    "except:\n",
    "    print('Failed to set memory growth to True')\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## CNN+BIGRU MODEL BASELINE\n",
    "1. TF-IDF, Max Features , Test Size\n",
    "\n",
    "Expected Result :\n",
    "1. test-size yang bagus untuk model ini.\n",
    "2. max Features terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T14:21:25.585244416Z",
     "start_time": "2023-05-19T14:21:25.493803180Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_data(test_size, max_features):\n",
    "  dataset = pd.read_csv('../../data/data_preprocessed/dataset/DatasetHateSpeech_Final_TA2023.csv', usecols=['preprocess_final', 'preprocess_token', 'label_final'])\n",
    "  # make data['label_fase_1'] to 0 and 1 binary classifier karena tensor hanya bisa input 0 =< label =< 1\n",
    "  dataset['label_final'] = dataset['label_final'].apply(lambda x: 1 if x == 'HS' else 0)\n",
    "  dataset.dropna(inplace=True)\n",
    "  \n",
    "  # feature extration\n",
    "  # Create a CountVectorizer object and fit it to the training data\n",
    "  vectorizer = TfidfVectorizer(ngram_range=(1,1), max_features=max_features)\n",
    "  vectorizer_data = vectorizer.fit_transform(dataset['preprocess_final'])\n",
    "\n",
    "  # to_pd\n",
    "  x_final = pd.DataFrame(vectorizer_data.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "  y_final = dataset['label_final'].copy()\n",
    "\n",
    "  # split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(x_final, y_final, test_size=test_size, random_state=0)\n",
    "  \n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T14:21:25.593980429Z",
     "start_time": "2023-05-19T14:21:25.503694668Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_cnn_bigru_model(X_train, y_train, X_test, y_test):\n",
    "  # reshape# reshape train and test data\n",
    "  X_train = np.array(X_train).reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "  X_test = np.array(X_test).reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "  model.add(MaxPooling1D(pool_size=3, strides=2, padding='same'))\n",
    "  model.add(Bidirectional(GRU(32, activation='relu', return_sequences=True)))\n",
    "  model.add(MaxPooling1D(pool_size=3, strides=2, padding='same'))\n",
    "  model.add(AveragePooling1D(pool_size=3, strides=2, padding='same'))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(units = 32, activation='relu'))\n",
    "  model.add(Dense(units=1, activation='sigmoid'))\n",
    "  opt = Adam(learning_rate=0.00005)\n",
    "  model.compile(optimizer=opt,loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  input_shape = X_train.shape\n",
    "  model.build(input_shape)\n",
    "  model.summary()\n",
    "  print()\n",
    "\n",
    "  model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data = (X_test, y_test))\n",
    "  loss = model.history.history['loss']\n",
    "  val_loss = model.history.history['val_loss']\n",
    "  score = model.evaluate(X_test, y_test, batch_size=64, verbose=0)\n",
    "\n",
    "  print()\n",
    "  print('Validation Accuracy:', score[1])\n",
    "  print('Validation Loss:', score[0])\n",
    "  print()\n",
    "\n",
    "  return model, loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T14:21:25.594604489Z",
     "start_time": "2023-05-19T14:21:25.548289001Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def call(test_size, max_features):\n",
    "  X_train, X_test, y_train, y_test = process_data(test_size, max_features)\n",
    "  model, loss, val_loss = create_cnn_bigru_model(X_train, y_train, X_test, y_test)\n",
    "  # predict\n",
    "  X_test = np.array(X_test).reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  # confusion matrix\n",
    "  classreport = classification_report(y_test, y_pred.round(), digits=4)\n",
    "  print()\n",
    "  print(classreport)\n",
    "  print()\n",
    "  accscore = accuracy_score(y_test, y_pred.round())\n",
    "  precscore = precision_score(y_test, y_pred.round(), zero_division=0)\n",
    "  recscore = recall_score(y_test, y_pred.round())\n",
    "  f1score = f1_score(y_test, y_pred.round(), average='weighted', zero_division=0)\n",
    "\n",
    "  return [accscore, precscore, recscore, f1score, loss, val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T14:21:28.258431037Z",
     "start_time": "2023-05-19T14:21:25.548687017Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (44856, 1, 32)            480032    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (44856, 1, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (44856, 1, 64)           12672     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (44856, 1, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (44856, 1, 64)           0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (44856, 64)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 494,817\n",
      "Trainable params: 494,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 16s 11ms/step - loss: 0.6691 - accuracy: 0.5870 - val_loss: 0.6054 - val_accuracy: 0.7454\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4992 - accuracy: 0.8310 - val_loss: 0.4172 - val_accuracy: 0.8614\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.3568 - accuracy: 0.8749 - val_loss: 0.3413 - val_accuracy: 0.8666\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.3068 - accuracy: 0.8826 - val_loss: 0.3249 - val_accuracy: 0.8658\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2882 - accuracy: 0.8886 - val_loss: 0.3226 - val_accuracy: 0.8662\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2780 - accuracy: 0.8928 - val_loss: 0.3218 - val_accuracy: 0.8680\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.2712 - accuracy: 0.8951 - val_loss: 0.3237 - val_accuracy: 0.8658\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2659 - accuracy: 0.8970 - val_loss: 0.3264 - val_accuracy: 0.8664\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2617 - accuracy: 0.8986 - val_loss: 0.3289 - val_accuracy: 0.8632\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2583 - accuracy: 0.9005 - val_loss: 0.3318 - val_accuracy: 0.8616\n",
      "\n",
      "Validation Accuracy: 0.8615847826004028\n",
      "Validation Loss: 0.3317703306674957\n",
      "\n",
      "156/156 [==============================] - 1s 2ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8536    0.8400    0.8467      2269\n",
      "           1     0.8681    0.8796    0.8738      2716\n",
      "\n",
      "    accuracy                         0.8616      4985\n",
      "   macro avg     0.8608    0.8598    0.8603      4985\n",
      "weighted avg     0.8615    0.8616    0.8615      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (44856, 1, 32)            480032    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (44856, 1, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (44856, 1, 64)           12672     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (44856, 1, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " average_pooling1d_1 (Averag  (44856, 1, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 494,817\n",
      "Trainable params: 494,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 10s 10ms/step - loss: 0.6687 - accuracy: 0.6571 - val_loss: 0.6009 - val_accuracy: 0.8391\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4717 - accuracy: 0.8589 - val_loss: 0.3815 - val_accuracy: 0.8620\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3337 - accuracy: 0.8737 - val_loss: 0.3306 - val_accuracy: 0.8666\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2985 - accuracy: 0.8819 - val_loss: 0.3219 - val_accuracy: 0.8674\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2836 - accuracy: 0.8890 - val_loss: 0.3204 - val_accuracy: 0.8682\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2744 - accuracy: 0.8936 - val_loss: 0.3207 - val_accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2680 - accuracy: 0.8956 - val_loss: 0.3242 - val_accuracy: 0.8692\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2629 - accuracy: 0.8979 - val_loss: 0.3267 - val_accuracy: 0.8678\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2589 - accuracy: 0.8997 - val_loss: 0.3286 - val_accuracy: 0.8664\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2556 - accuracy: 0.9014 - val_loss: 0.3316 - val_accuracy: 0.8640\n",
      "\n",
      "Validation Accuracy: 0.8639919757843018\n",
      "Validation Loss: 0.3315577507019043\n",
      "\n",
      "156/156 [==============================] - 1s 2ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8572    0.8413    0.8492      2269\n",
      "           1     0.8695    0.8829    0.8761      2716\n",
      "\n",
      "    accuracy                         0.8640      4985\n",
      "   macro avg     0.8633    0.8621    0.8627      4985\n",
      "weighted avg     0.8639    0.8640    0.8639      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (44856, 1, 32)            480032    \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (44856, 1, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (44856, 1, 64)           12672     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (44856, 1, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " average_pooling1d_2 (Averag  (44856, 1, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 494,817\n",
      "Trainable params: 494,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 10s 11ms/step - loss: 0.6677 - accuracy: 0.6238 - val_loss: 0.6017 - val_accuracy: 0.7785\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4833 - accuracy: 0.8448 - val_loss: 0.3935 - val_accuracy: 0.8622\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3405 - accuracy: 0.8754 - val_loss: 0.3346 - val_accuracy: 0.8674\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3004 - accuracy: 0.8835 - val_loss: 0.3220 - val_accuracy: 0.8690\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2841 - accuracy: 0.8898 - val_loss: 0.3201 - val_accuracy: 0.8682\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2747 - accuracy: 0.8933 - val_loss: 0.3218 - val_accuracy: 0.8684\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2681 - accuracy: 0.8958 - val_loss: 0.3236 - val_accuracy: 0.8672\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2629 - accuracy: 0.8981 - val_loss: 0.3259 - val_accuracy: 0.8654\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2587 - accuracy: 0.8999 - val_loss: 0.3305 - val_accuracy: 0.8634\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2551 - accuracy: 0.9013 - val_loss: 0.3310 - val_accuracy: 0.8614\n",
      "\n",
      "Validation Accuracy: 0.8613841533660889\n",
      "Validation Loss: 0.33103662729263306\n",
      "\n",
      "156/156 [==============================] - 1s 2ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8504    0.8440    0.8472      2269\n",
      "           1     0.8705    0.8759    0.8732      2716\n",
      "\n",
      "    accuracy                         0.8614      4985\n",
      "   macro avg     0.8604    0.8600    0.8602      4985\n",
      "weighted avg     0.8613    0.8614    0.8613      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (44856, 1, 32)            480032    \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (44856, 1, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (44856, 1, 64)           12672     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (44856, 1, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " average_pooling1d_3 (Averag  (44856, 1, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 494,817\n",
      "Trainable params: 494,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 11s 11ms/step - loss: 0.6630 - accuracy: 0.5902 - val_loss: 0.5913 - val_accuracy: 0.7314\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4948 - accuracy: 0.8269 - val_loss: 0.4233 - val_accuracy: 0.8610\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3644 - accuracy: 0.8755 - val_loss: 0.3468 - val_accuracy: 0.8652\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3106 - accuracy: 0.8833 - val_loss: 0.3276 - val_accuracy: 0.8664\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2908 - accuracy: 0.8886 - val_loss: 0.3245 - val_accuracy: 0.8668\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2803 - accuracy: 0.8925 - val_loss: 0.3263 - val_accuracy: 0.8666\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2737 - accuracy: 0.8953 - val_loss: 0.3265 - val_accuracy: 0.8642\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2691 - accuracy: 0.8964 - val_loss: 0.3289 - val_accuracy: 0.8646\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2655 - accuracy: 0.8974 - val_loss: 0.3331 - val_accuracy: 0.8618\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2626 - accuracy: 0.8993 - val_loss: 0.3342 - val_accuracy: 0.8614\n",
      "\n",
      "Validation Accuracy: 0.8613841533660889\n",
      "Validation Loss: 0.3342387080192566\n",
      "\n",
      "156/156 [==============================] - 1s 2ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8494    0.8453    0.8474      2269\n",
      "           1     0.8713    0.8748    0.8730      2716\n",
      "\n",
      "    accuracy                         0.8614      4985\n",
      "   macro avg     0.8604    0.8601    0.8602      4985\n",
      "weighted avg     0.8613    0.8614    0.8614      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (44856, 1, 32)            480032    \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (44856, 1, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (44856, 1, 64)           12672     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (44856, 1, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " average_pooling1d_4 (Averag  (44856, 1, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 494,817\n",
      "Trainable params: 494,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 10s 10ms/step - loss: 0.6702 - accuracy: 0.6090 - val_loss: 0.6051 - val_accuracy: 0.7671\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4885 - accuracy: 0.8428 - val_loss: 0.4014 - val_accuracy: 0.8624\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3469 - accuracy: 0.8745 - val_loss: 0.3373 - val_accuracy: 0.8666\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3043 - accuracy: 0.8823 - val_loss: 0.3258 - val_accuracy: 0.8694\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2877 - accuracy: 0.8883 - val_loss: 0.3217 - val_accuracy: 0.8674\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2779 - accuracy: 0.8923 - val_loss: 0.3230 - val_accuracy: 0.8688\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.2710 - accuracy: 0.8953 - val_loss: 0.3237 - val_accuracy: 0.8678\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2659 - accuracy: 0.8971 - val_loss: 0.3263 - val_accuracy: 0.8668\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2617 - accuracy: 0.8990 - val_loss: 0.3286 - val_accuracy: 0.8650\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2581 - accuracy: 0.9007 - val_loss: 0.3310 - val_accuracy: 0.8644\n",
      "\n",
      "Validation Accuracy: 0.8643931746482849\n",
      "Validation Loss: 0.3310117721557617\n",
      "\n",
      "156/156 [==============================] - 1s 2ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8570    0.8427    0.8498      2269\n",
      "           1     0.8704    0.8825    0.8764      2716\n",
      "\n",
      "    accuracy                         0.8644      4985\n",
      "   macro avg     0.8637    0.8626    0.8631      4985\n",
      "weighted avg     0.8643    0.8644    0.8643      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (44856, 1, 32)            960032    \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (44856, 1, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (44856, 1, 64)           12672     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (44856, 1, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_5 (Averag  (44856, 1, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 974,817\n",
      "Trainable params: 974,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 11s 11ms/step - loss: 0.6662 - accuracy: 0.6324 - val_loss: 0.5996 - val_accuracy: 0.8034\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4802 - accuracy: 0.8544 - val_loss: 0.3922 - val_accuracy: 0.8656\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3342 - accuracy: 0.8789 - val_loss: 0.3300 - val_accuracy: 0.8666\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2882 - accuracy: 0.8886 - val_loss: 0.3177 - val_accuracy: 0.8678\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2672 - accuracy: 0.8978 - val_loss: 0.3162 - val_accuracy: 0.8704\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2533 - accuracy: 0.9044 - val_loss: 0.3187 - val_accuracy: 0.8690\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2429 - accuracy: 0.9085 - val_loss: 0.3237 - val_accuracy: 0.8678\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2343 - accuracy: 0.9131 - val_loss: 0.3285 - val_accuracy: 0.8652\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2272 - accuracy: 0.9163 - val_loss: 0.3350 - val_accuracy: 0.8642\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2210 - accuracy: 0.9193 - val_loss: 0.3416 - val_accuracy: 0.8616\n",
      "\n",
      "Validation Accuracy: 0.8615847826004028\n",
      "Validation Loss: 0.3416490852832794\n",
      "\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8504    0.8444    0.8474      2269\n",
      "           1     0.8708    0.8759    0.8733      2716\n",
      "\n",
      "    accuracy                         0.8616      4985\n",
      "   macro avg     0.8606    0.8602    0.8604      4985\n",
      "weighted avg     0.8615    0.8616    0.8615      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (44856, 1, 32)            960032    \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (44856, 1, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (44856, 1, 64)           12672     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (44856, 1, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_6 (Averag  (44856, 1, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 974,817\n",
      "Trainable params: 974,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 11s 11ms/step - loss: 0.6662 - accuracy: 0.6528 - val_loss: 0.5970 - val_accuracy: 0.8090\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4751 - accuracy: 0.8574 - val_loss: 0.3868 - val_accuracy: 0.8646\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3298 - accuracy: 0.8799 - val_loss: 0.3277 - val_accuracy: 0.8684\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2858 - accuracy: 0.8903 - val_loss: 0.3175 - val_accuracy: 0.8706\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2656 - accuracy: 0.8989 - val_loss: 0.3167 - val_accuracy: 0.8726\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2523 - accuracy: 0.9049 - val_loss: 0.3198 - val_accuracy: 0.8704\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2421 - accuracy: 0.9086 - val_loss: 0.3246 - val_accuracy: 0.8680\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2338 - accuracy: 0.9129 - val_loss: 0.3303 - val_accuracy: 0.8656\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2267 - accuracy: 0.9167 - val_loss: 0.3367 - val_accuracy: 0.8634\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2203 - accuracy: 0.9192 - val_loss: 0.3435 - val_accuracy: 0.8616\n",
      "\n",
      "Validation Accuracy: 0.8615847826004028\n",
      "Validation Loss: 0.34351059794425964\n",
      "\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8510    0.8435    0.8473      2269\n",
      "           1     0.8702    0.8767    0.8734      2716\n",
      "\n",
      "    accuracy                         0.8616      4985\n",
      "   macro avg     0.8606    0.8601    0.8604      4985\n",
      "weighted avg     0.8615    0.8616    0.8615      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_7 (Conv1D)           (44856, 1, 32)            960032    \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (44856, 1, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (44856, 1, 64)           12672     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (44856, 1, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_7 (Averag  (44856, 1, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 974,817\n",
      "Trainable params: 974,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 11s 11ms/step - loss: 0.6627 - accuracy: 0.6037 - val_loss: 0.5949 - val_accuracy: 0.7448\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4980 - accuracy: 0.8318 - val_loss: 0.4288 - val_accuracy: 0.8648\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3639 - accuracy: 0.8812 - val_loss: 0.3492 - val_accuracy: 0.8692\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2996 - accuracy: 0.8923 - val_loss: 0.3268 - val_accuracy: 0.8698\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.2713 - accuracy: 0.8991 - val_loss: 0.3223 - val_accuracy: 0.8698\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.2555 - accuracy: 0.9052 - val_loss: 0.3248 - val_accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2446 - accuracy: 0.9101 - val_loss: 0.3300 - val_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2362 - accuracy: 0.9142 - val_loss: 0.3383 - val_accuracy: 0.8616\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2293 - accuracy: 0.9160 - val_loss: 0.3446 - val_accuracy: 0.8598\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2230 - accuracy: 0.9199 - val_loss: 0.3506 - val_accuracy: 0.8578\n",
      "\n",
      "Validation Accuracy: 0.8577733039855957\n",
      "Validation Loss: 0.3505610227584839\n",
      "\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8412    0.8475    0.8443      2269\n",
      "           1     0.8718    0.8663    0.8691      2716\n",
      "\n",
      "    accuracy                         0.8578      4985\n",
      "   macro avg     0.8565    0.8569    0.8567      4985\n",
      "weighted avg     0.8579    0.8578    0.8578      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (44856, 1, 32)            960032    \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPoolin  (44856, 1, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (44856, 1, 64)           12672     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  (44856, 1, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_8 (Averag  (44856, 1, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 974,817\n",
      "Trainable params: 974,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 11s 12ms/step - loss: 0.6678 - accuracy: 0.6220 - val_loss: 0.6034 - val_accuracy: 0.7860\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4873 - accuracy: 0.8470 - val_loss: 0.3975 - val_accuracy: 0.8640\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3362 - accuracy: 0.8805 - val_loss: 0.3307 - val_accuracy: 0.8680\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2877 - accuracy: 0.8904 - val_loss: 0.3185 - val_accuracy: 0.8680\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2664 - accuracy: 0.8988 - val_loss: 0.3188 - val_accuracy: 0.8708\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2529 - accuracy: 0.9043 - val_loss: 0.3206 - val_accuracy: 0.8690\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2431 - accuracy: 0.9089 - val_loss: 0.3261 - val_accuracy: 0.8682\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2352 - accuracy: 0.9128 - val_loss: 0.3329 - val_accuracy: 0.8658\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2288 - accuracy: 0.9158 - val_loss: 0.3390 - val_accuracy: 0.8634\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2231 - accuracy: 0.9179 - val_loss: 0.3465 - val_accuracy: 0.8604\n",
      "\n",
      "Validation Accuracy: 0.8603811264038086\n",
      "Validation Loss: 0.3465142846107483\n",
      "\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8532    0.8374    0.8452      2269\n",
      "           1     0.8662    0.8796    0.8729      2716\n",
      "\n",
      "    accuracy                         0.8604      4985\n",
      "   macro avg     0.8597    0.8585    0.8590      4985\n",
      "weighted avg     0.8603    0.8604    0.8603      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_9 (Conv1D)           (44856, 1, 32)            960032    \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (44856, 1, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (44856, 1, 64)           12672     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPoolin  (44856, 1, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_9 (Averag  (44856, 1, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 974,817\n",
      "Trainable params: 974,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 10s 11ms/step - loss: 0.6668 - accuracy: 0.6238 - val_loss: 0.5987 - val_accuracy: 0.7803\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4779 - accuracy: 0.8511 - val_loss: 0.3885 - val_accuracy: 0.8650\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3312 - accuracy: 0.8791 - val_loss: 0.3280 - val_accuracy: 0.8690\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2861 - accuracy: 0.8899 - val_loss: 0.3182 - val_accuracy: 0.8668\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2658 - accuracy: 0.8983 - val_loss: 0.3177 - val_accuracy: 0.8718\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2525 - accuracy: 0.9043 - val_loss: 0.3207 - val_accuracy: 0.8710\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2425 - accuracy: 0.9091 - val_loss: 0.3258 - val_accuracy: 0.8672\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2345 - accuracy: 0.9123 - val_loss: 0.3311 - val_accuracy: 0.8652\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2278 - accuracy: 0.9154 - val_loss: 0.3378 - val_accuracy: 0.8638\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2220 - accuracy: 0.9186 - val_loss: 0.3453 - val_accuracy: 0.8604\n",
      "\n",
      "Validation Accuracy: 0.8603811264038086\n",
      "Validation Loss: 0.34529390931129456\n",
      "\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8580    0.8308    0.8442      2269\n",
      "           1     0.8623    0.8851    0.8735      2716\n",
      "\n",
      "    accuracy                         0.8604      4985\n",
      "   macro avg     0.8601    0.8579    0.8589      4985\n",
      "weighted avg     0.8603    0.8604    0.8602      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_10 (Conv1D)          (44856, 1, 32)            1440032   \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (44856, 1, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (44856, 1, 64)           12672     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (44856, 1, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_10 (Avera  (44856, 1, 64)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,454,817\n",
      "Trainable params: 1,454,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 11s 12ms/step - loss: 0.6673 - accuracy: 0.7131 - val_loss: 0.5968 - val_accuracy: 0.8526\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4693 - accuracy: 0.8655 - val_loss: 0.3820 - val_accuracy: 0.8674\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3209 - accuracy: 0.8825 - val_loss: 0.3249 - val_accuracy: 0.8682\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2735 - accuracy: 0.8958 - val_loss: 0.3161 - val_accuracy: 0.8688\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2500 - accuracy: 0.9063 - val_loss: 0.3166 - val_accuracy: 0.8678\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2336 - accuracy: 0.9144 - val_loss: 0.3223 - val_accuracy: 0.8664\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2210 - accuracy: 0.9210 - val_loss: 0.3303 - val_accuracy: 0.8632\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2105 - accuracy: 0.9248 - val_loss: 0.3400 - val_accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2015 - accuracy: 0.9293 - val_loss: 0.3502 - val_accuracy: 0.8580\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.1933 - accuracy: 0.9328 - val_loss: 0.3614 - val_accuracy: 0.8544\n",
      "\n",
      "Validation Accuracy: 0.8543630838394165\n",
      "Validation Loss: 0.36135223507881165\n",
      "\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8505    0.8250    0.8376      2269\n",
      "           1     0.8574    0.8789    0.8680      2716\n",
      "\n",
      "    accuracy                         0.8544      4985\n",
      "   macro avg     0.8540    0.8519    0.8528      4985\n",
      "weighted avg     0.8543    0.8544    0.8542      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_11 (Conv1D)          (44856, 1, 32)            1440032   \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (44856, 1, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (44856, 1, 64)           12672     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (44856, 1, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_11 (Avera  (44856, 1, 64)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,454,817\n",
      "Trainable params: 1,454,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 10s 11ms/step - loss: 0.6640 - accuracy: 0.6489 - val_loss: 0.5927 - val_accuracy: 0.8002\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4692 - accuracy: 0.8593 - val_loss: 0.3830 - val_accuracy: 0.8644\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3224 - accuracy: 0.8839 - val_loss: 0.3269 - val_accuracy: 0.8690\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2754 - accuracy: 0.8962 - val_loss: 0.3189 - val_accuracy: 0.8672\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2527 - accuracy: 0.9056 - val_loss: 0.3188 - val_accuracy: 0.8684\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2371 - accuracy: 0.9127 - val_loss: 0.3248 - val_accuracy: 0.8652\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2251 - accuracy: 0.9179 - val_loss: 0.3316 - val_accuracy: 0.8616\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2153 - accuracy: 0.9224 - val_loss: 0.3400 - val_accuracy: 0.8600\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2069 - accuracy: 0.9259 - val_loss: 0.3505 - val_accuracy: 0.8568\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.1996 - accuracy: 0.9294 - val_loss: 0.3604 - val_accuracy: 0.8564\n",
      "\n",
      "Validation Accuracy: 0.8563690781593323\n",
      "Validation Loss: 0.36038506031036377\n",
      "\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8450    0.8383    0.8416      2269\n",
      "           1     0.8658    0.8715    0.8686      2716\n",
      "\n",
      "    accuracy                         0.8564      4985\n",
      "   macro avg     0.8554    0.8549    0.8551      4985\n",
      "weighted avg     0.8563    0.8564    0.8563      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (44856, 1, 32)            1440032   \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPoolin  (44856, 1, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (44856, 1, 64)           12672     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPoolin  (44856, 1, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_12 (Avera  (44856, 1, 64)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,454,817\n",
      "Trainable params: 1,454,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 21s 11ms/step - loss: 0.6675 - accuracy: 0.6351 - val_loss: 0.6066 - val_accuracy: 0.8118\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.4920 - accuracy: 0.8570 - val_loss: 0.4005 - val_accuracy: 0.8626\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.3348 - accuracy: 0.8811 - val_loss: 0.3305 - val_accuracy: 0.8670\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.2816 - accuracy: 0.8930 - val_loss: 0.3176 - val_accuracy: 0.8694\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.2574 - accuracy: 0.9021 - val_loss: 0.3170 - val_accuracy: 0.8696\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.2412 - accuracy: 0.9099 - val_loss: 0.3208 - val_accuracy: 0.8680\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2289 - accuracy: 0.9154 - val_loss: 0.3268 - val_accuracy: 0.8634\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2187 - accuracy: 0.9199 - val_loss: 0.3347 - val_accuracy: 0.8624\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.2100 - accuracy: 0.9244 - val_loss: 0.3437 - val_accuracy: 0.8586\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2025 - accuracy: 0.9273 - val_loss: 0.3531 - val_accuracy: 0.8570\n",
      "\n",
      "Validation Accuracy: 0.8569709062576294\n",
      "Validation Loss: 0.3531084954738617\n",
      "\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8489    0.8343    0.8415      2269\n",
      "           1     0.8635    0.8759    0.8697      2716\n",
      "\n",
      "    accuracy                         0.8570      4985\n",
      "   macro avg     0.8562    0.8551    0.8556      4985\n",
      "weighted avg     0.8569    0.8570    0.8569      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_13 (Conv1D)          (44856, 1, 32)            1440032   \n",
      "                                                                 \n",
      " max_pooling1d_26 (MaxPoolin  (44856, 1, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (44856, 1, 64)           12672     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " max_pooling1d_27 (MaxPoolin  (44856, 1, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_13 (Avera  (44856, 1, 64)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,454,817\n",
      "Trainable params: 1,454,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 11s 12ms/step - loss: 0.6664 - accuracy: 0.6587 - val_loss: 0.6005 - val_accuracy: 0.8381\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.4751 - accuracy: 0.8639 - val_loss: 0.3849 - val_accuracy: 0.8634\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.3231 - accuracy: 0.8828 - val_loss: 0.3264 - val_accuracy: 0.8654\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.2756 - accuracy: 0.8949 - val_loss: 0.3174 - val_accuracy: 0.8668\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.2526 - accuracy: 0.9053 - val_loss: 0.3186 - val_accuracy: 0.8678\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2367 - accuracy: 0.9121 - val_loss: 0.3233 - val_accuracy: 0.8668\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2242 - accuracy: 0.9183 - val_loss: 0.3305 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 7s 10ms/step - loss: 0.2138 - accuracy: 0.9226 - val_loss: 0.3388 - val_accuracy: 0.8628\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 7s 11ms/step - loss: 0.2048 - accuracy: 0.9273 - val_loss: 0.3488 - val_accuracy: 0.8588\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.1968 - accuracy: 0.9309 - val_loss: 0.3595 - val_accuracy: 0.8564\n",
      "\n",
      "Validation Accuracy: 0.8563690781593323\n",
      "Validation Loss: 0.3594793379306793\n",
      "\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8416    0.8431    0.8424      2269\n",
      "           1     0.8687    0.8675    0.8681      2716\n",
      "\n",
      "    accuracy                         0.8564      4985\n",
      "   macro avg     0.8552    0.8553    0.8552      4985\n",
      "weighted avg     0.8564    0.8564    0.8564      4985\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer gru_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_14 (Conv1D)          (44856, 1, 32)            1440032   \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPoolin  (44856, 1, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (44856, 1, 64)           12672     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPoolin  (44856, 1, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_14 (Avera  (44856, 1, 64)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (44856, 64)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (44856, 32)               2080      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (44856, 1)                33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,454,817\n",
      "Trainable params: 1,454,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      "701/701 [==============================] - 12s 12ms/step - loss: 0.6686 - accuracy: 0.5844 - val_loss: 0.6092 - val_accuracy: 0.7037\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.5044 - accuracy: 0.8226 - val_loss: 0.4228 - val_accuracy: 0.8622\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.3528 - accuracy: 0.8822 - val_loss: 0.3404 - val_accuracy: 0.8646\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2890 - accuracy: 0.8929 - val_loss: 0.3211 - val_accuracy: 0.8682\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 9s 12ms/step - loss: 0.2614 - accuracy: 0.9025 - val_loss: 0.3204 - val_accuracy: 0.8678\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2444 - accuracy: 0.9097 - val_loss: 0.3238 - val_accuracy: 0.8680\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2319 - accuracy: 0.9152 - val_loss: 0.3298 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2219 - accuracy: 0.9197 - val_loss: 0.3385 - val_accuracy: 0.8630\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2133 - accuracy: 0.9235 - val_loss: 0.3478 - val_accuracy: 0.8592\n",
      "Epoch 10/10\n",
      "701/701 [==============================] - 8s 11ms/step - loss: 0.2059 - accuracy: 0.9272 - val_loss: 0.3566 - val_accuracy: 0.8560\n",
      "\n",
      "Validation Accuracy: 0.8559678792953491\n",
      "Validation Loss: 0.3566308915615082\n",
      "\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8367    0.8493    0.8430      2269\n",
      "           1     0.8725    0.8616    0.8670      2716\n",
      "\n",
      "    accuracy                         0.8560      4985\n",
      "   macro avg     0.8546    0.8554    0.8550      4985\n",
      "weighted avg     0.8562    0.8560    0.8560      4985\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size = [0.1]\n",
    "max_features = [5000, 10000, 15000]\n",
    "result = []\n",
    "count = 1\n",
    "for idx, value_testsize in enumerate(test_size):\n",
    "  for idx_max, value_features in enumerate(max_features):\n",
    "    for i in range(5):\n",
    "      result.append([count] + [value_testsize] + [value_features] + call(value_testsize, value_features))\n",
    "      count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-19T14:21:28.257900790Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_func(df):\n",
    "  for idx, val in enumerate(df['No']):\n",
    "    plt.plot(df['Loss'].iloc[idx], label=f'Test Size {val}')\n",
    "    plt.plot(df['Val Loss'].iloc[idx], label=f'Test Size {val}')\n",
    "    plt.title(f'baseline CNN-BiGRU lfg {df[\"Test_Size\"].iloc[idx]} max_features {df[\"Max_Features\"].iloc[idx]}-{idx}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.savefig(f'hasil/grafik/cnn+bigru/lfg_baselineCNNBiGRU_testSize{df[\"Test_Size\"].iloc[idx]}-{idx}-max_features{df[\"Max_Features\"].iloc[idx]}.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score by Test Size\n",
      "Test Size 0.1 & max features 5000\n",
      "Average Accuracy Score : 0.8625476429287865\n",
      "Average Precision Score : 0.8699392137978619\n",
      "Average Recall Score : 0.8791605301914579\n",
      "Average F1 Score : 0.8624705377001494\n",
      "\n",
      "Test_Size 0.1 & max features 10000\n",
      "Average Accuracy Score : 0.8603410230692077\n",
      "Average Precision Score : 0.8682635588407344\n",
      "Average Recall Score : 0.8767304860088366\n",
      "Average F1 Score : 0.8602648798708671\n",
      "\n",
      "Test_Size 0.1 & max features 20000\n",
      "Average Accuracy Score : 0.8560080240722167\n",
      "Average Precision Score : 0.865579905804951\n",
      "Average Recall Score : 0.8710603829160529\n",
      "Average F1 Score : 0.8559532001026213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(result, columns=['No', 'Test_Size', 'Max_Features', 'Accuracy Score', 'Precision Score', 'Recall Score', 'F1 Score', 'Loss', 'Val Loss'])\n",
    "df.to_csv('hasil/baseline_CNNbiGRU-1.csv', index=False)\n",
    "loss_func(df)\n",
    "\n",
    "# print average score by test size\n",
    "print('Average Score by Test Size')\n",
    "print('Test Size 0.1 & max features 5000')\n",
    "print('Average Accuracy Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 5000)]['Accuracy Score'].mean())\n",
    "print('Average Precision Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 5000)]['Precision Score'].mean())\n",
    "print('Average Recall Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 5000)]['Recall Score'].mean())\n",
    "print('Average F1 Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 5000)]['F1 Score'].mean())\n",
    "print()\n",
    "print('Test_Size 0.1 & max features 10000')\n",
    "print('Average Accuracy Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 10000)]['Accuracy Score'].mean())\n",
    "print('Average Precision Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 10000)]['Precision Score'].mean())\n",
    "print('Average Recall Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 10000)]['Recall Score'].mean())\n",
    "print('Average F1 Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 10000)]['F1 Score'].mean())\n",
    "print()\n",
    "print('Test_Size 0.1 & max features 20000')\n",
    "print('Average Accuracy Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 15000)]['Accuracy Score'].mean())\n",
    "print('Average Precision Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 15000)]['Precision Score'].mean())\n",
    "print('Average Recall Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 15000)]['Recall Score'].mean())\n",
    "print('Average F1 Score :', df[(df['Test_Size'] == 0.1) & (df['Max_Features'] == 15000)]['F1 Score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Test_Size 0.2 & max features 5000')\n",
    "print('Average Accuracy Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 5000)]['Accuracy Score'].mean())\n",
    "print('Average Precision Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 5000)]['Precision Score'].mean())\n",
    "print('Average Recall Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 5000)]['Recall Score'].mean())\n",
    "print('Average F1 Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 5000)]['F1 Score'].mean())\n",
    "print()\n",
    "print('Test_Size 0.2 & max features 10000')\n",
    "print('Average Accuracy Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 10000)]['Accuracy Score'].mean())\n",
    "print('Average Precision Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 10000)]['Precision Score'].mean())\n",
    "print('Average Recall Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 10000)]['Recall Score'].mean())\n",
    "print('Average F1 Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 10000)]['F1 Score'].mean())\n",
    "print()\n",
    "print('Test_Size 0.2 & max features 20000')\n",
    "print('Average Accuracy Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 20000)]['Accuracy Score'].mean())\n",
    "print('Average Precision Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 20000)]['Precision Score'].mean())\n",
    "print('Average Recall Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 20000)]['Recall Score'].mean())\n",
    "print('Average F1 Score :', df[(df['Test_Size'] == 0.2) & (df['Max_Features'] == 20000)]['F1 Score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Test_Size 0.3 & max features 5000')\n",
    "print('Average Accuracy Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 5000)]['Accuracy Score'].mean())\n",
    "print('Average Precision Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 5000)]['Precision Score'].mean())\n",
    "print('Average Recall Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 5000)]['Recall Score'].mean())\n",
    "print('Average F1 Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 5000)]['F1 Score'].mean())\n",
    "print()\n",
    "print('Test_Size 0.3 & max features 10000')\n",
    "print('Average Accuracy Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 10000)]['Accuracy Score'].mean())\n",
    "print('Average Precision Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 10000)]['Precision Score'].mean())\n",
    "print('Average Recall Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 10000)]['Recall Score'].mean())\n",
    "print('Average F1 Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 10000)]['F1 Score'].mean())\n",
    "print()\n",
    "print('Test_Size 0.3 & max features 20000')\n",
    "print('Average Accuracy Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 20000)]['Accuracy Score'].mean())\n",
    "print('Average Precision Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 20000)]['Precision Score'].mean())\n",
    "print('Average Recall Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 20000)]['Recall Score'].mean())\n",
    "print('Average F1 Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 20000)]['F1 Score'].mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
