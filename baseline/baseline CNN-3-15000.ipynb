{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Baseline Deteksi Ujaran Kebencian Metode CNN\n",
    "Copyright@ I Gde Bagus Janardana Abasan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T14:18:23.499525249Z",
     "start_time": "2023-05-19T14:18:08.300318407Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, Bidirectional, AveragePooling1D, LSTM, GRU, Conv1D, MaxPooling1D, Flatten, GlobalMaxPooling1D, CuDNNGRU , GlobalAveragePooling1D, Concatenate, TimeDistributed\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## CNN MODEL BASELINE\n",
    "1. Tanpa TF-IDF ( CountVectorize )\n",
    "2. Testing Test Size ( splitting )\n",
    "\n",
    "Expected Result :\n",
    "1. test-size yang bagus untuk model ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T14:18:26.210514500Z",
     "start_time": "2023-05-19T14:18:23.504046608Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'compute_capability': (7, 5), 'device_name': 'Tesla T4'}\n",
      "Found PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') GPU(s)\n",
      "Memory growth set to True, using Nvidia Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan informasi perangkat GPU yang digunakan\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    device_details = tf.config.experimental.get_device_details(device)\n",
    "    print(device_details)\n",
    "\n",
    "try:\n",
    "    print(f'Found {physical_devices[0]} GPU(s)')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    assert tf.config.experimental.get_memory_growth(physical_devices[0])\n",
    "    print('Memory growth set to True, using Nvidia Tesla T4')\n",
    "except:\n",
    "    print('Failed to set memory growth to True')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T14:18:26.306134849Z",
     "start_time": "2023-05-19T14:18:26.215791588Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_data(test_size, max_features):\n",
    "  dataset = pd.read_csv('../../data/data_preprocessed/dataset/DatasetHateSpeech_Final_TA2023.csv', usecols=['preprocess_final', 'preprocess_token', 'label_final'])\n",
    "  # make data['label_fase_1'] to 0 and 1 binary classifier karena tensor hanya bisa input 0 =< label =< 1\n",
    "  dataset['label_final'] = dataset['label_final'].apply(lambda x: 1 if x == 'HS' else 0)\n",
    "  dataset.dropna(inplace=True)\n",
    "\n",
    "  # feature extration\n",
    "  # Create a CountVectorizer object and fit it to the training data\n",
    "  vectorizer = TfidfVectorizer(ngram_range=(1,1), max_features=max_features)\n",
    "  vectorizer_data = vectorizer.fit_transform(dataset['preprocess_final'])\n",
    "\n",
    "  # to_pd\n",
    "  x_final = pd.DataFrame(vectorizer_data.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "  y_final = dataset['label_final'].copy()\n",
    "\n",
    "  # split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(x_final, y_final, test_size=test_size, random_state=0)\n",
    "\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T14:18:26.324280577Z",
     "start_time": "2023-05-19T14:18:26.226100086Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(X_train, X_test, y_train, y_test):\n",
    "  # reshape\n",
    "  X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "  X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "  # CNN model\n",
    "  model = Sequential()\n",
    "  model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "  model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(units=32, activation='relu'))\n",
    "  model.add(Dense(units=1, activation='sigmoid'))\n",
    "  optimizer = Adam(learning_rate=0.00001)\n",
    "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.build(input_shape=(None, X_train.shape[1], 1))\n",
    "  model.summary()\n",
    "  \n",
    "  with tf.device('/cpu:0'):\n",
    "    x = tf.convert_to_tensor(X_train, np.float32)\n",
    "    y = tf.convert_to_tensor(y_train, np.float32)\n",
    "    \n",
    "  model.fit(x, y, validation_data=(X_test, y_test), epochs=10, batch_size=64)\n",
    "  loss = model.history.history['loss']\n",
    "  val_loss = model.history.history['val_loss']\n",
    "  print(\"=== MODEL EVALUATE TEST DATA ===\")\n",
    "  score = model.evaluate(X_test, y_test, batch_size=64, verbose=0)\n",
    "  print()\n",
    "  print('Validation Accuracy:', score[1])\n",
    "  print('Validation Loss:', score[0])\n",
    "  print()\n",
    "\n",
    "  return model, loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(X_train, X_test, y_train, y_test):\n",
    "  # reshape\n",
    "  X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "  X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "  # CNN model\n",
    "  model = Sequential()\n",
    "  model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "  model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(units=32, activation='relu'))\n",
    "  model.add(Dense(units=1, activation='sigmoid'))\n",
    "  optimizer = Adam(learning_rate=0.00001)\n",
    "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.build(input_shape=(None, X_train.shape[1], 1))\n",
    "  model.summary()\n",
    "  \n",
    "  with tf.device('/cpu:0'):\n",
    "    x = tf.convert_to_tensor(X_train, np.float32)\n",
    "    y = tf.convert_to_tensor(y_train, np.float32)\n",
    "    \n",
    "  model.fit(x, y, validation_data=(X_test, y_test), epochs=10, batch_size=64)\n",
    "  loss = model.history.history['loss']\n",
    "  val_loss = model.history.history['val_loss']\n",
    "  print(\"=== MODEL EVALUATE TEST DATA ===\")\n",
    "  score = model.evaluate(X_test, y_test, batch_size=64, verbose=0)\n",
    "  print()\n",
    "  print('Validation Accuracy:', score[1])\n",
    "  print('Validation Loss:', score[0])\n",
    "  print()\n",
    "\n",
    "  return model, loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T14:18:26.324842651Z",
     "start_time": "2023-05-19T14:18:26.235203729Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def call(test_size, max_features):\n",
    "  X_train, X_test, y_train, y_test = process_data(test_size, max_features)\n",
    "  model, loss, val_loss = create_cnn_model(X_train, X_test, y_train, y_test)\n",
    "   # predict\n",
    "  y_pred = model.predict(X_test)\n",
    "  print('using test size :', test_size)\n",
    "  print()\n",
    "\n",
    "  # confusion matrix\n",
    "  classreport = classification_report(y_test, y_pred.round(), digits=4)\n",
    "  print()\n",
    "  print(classreport)\n",
    "  print()\n",
    "  accscore = accuracy_score(y_test, y_pred.round())\n",
    "  precscore = precision_score(y_test, y_pred.round(), zero_division=0)\n",
    "  recscore = recall_score(y_test, y_pred.round())\n",
    "  f1score = f1_score(y_test, y_pred.round(), average='weighted', zero_division=0)\n",
    "\n",
    "  return [accscore, precscore, recscore, f1score, loss, val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-19T14:18:26.256068687Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 15000, 32)         128       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 7500, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 240000)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7680032   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,680,193\n",
      "Trainable params: 7,680,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "546/546 [==============================] - 18s 29ms/step - loss: 0.6820 - accuracy: 0.5515 - val_loss: 0.6730 - val_accuracy: 0.5481\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6632 - accuracy: 0.5772 - val_loss: 0.6552 - val_accuracy: 0.6785\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6433 - accuracy: 0.6676 - val_loss: 0.6353 - val_accuracy: 0.6525\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6217 - accuracy: 0.7396 - val_loss: 0.6152 - val_accuracy: 0.6791\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5992 - accuracy: 0.7839 - val_loss: 0.5930 - val_accuracy: 0.8275\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5768 - accuracy: 0.8163 - val_loss: 0.5717 - val_accuracy: 0.8055\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5547 - accuracy: 0.8356 - val_loss: 0.5521 - val_accuracy: 0.7972\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5334 - accuracy: 0.8442 - val_loss: 0.5318 - val_accuracy: 0.8290\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5134 - accuracy: 0.8500 - val_loss: 0.5135 - val_accuracy: 0.8382\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4943 - accuracy: 0.8563 - val_loss: 0.4967 - val_accuracy: 0.8404\n",
      "=== MODEL EVALUATE TEST DATA ===\n",
      "\n",
      "Validation Accuracy: 0.8404333591461182\n",
      "Validation Loss: 0.4967135190963745\n",
      "\n",
      "468/468 [==============================] - 3s 6ms/step\n",
      "using test size : 0.3\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9052    0.7253    0.8053      6803\n",
      "           1     0.8033    0.9366    0.8648      8150\n",
      "\n",
      "    accuracy                         0.8404     14953\n",
      "   macro avg     0.8542    0.8309    0.8351     14953\n",
      "weighted avg     0.8496    0.8404    0.8377     14953\n",
      "\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 15000, 32)         128       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 7500, 32)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 240000)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                7680032   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,680,193\n",
      "Trainable params: 7,680,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "546/546 [==============================] - 16s 28ms/step - loss: 0.6798 - accuracy: 0.5483 - val_loss: 0.6683 - val_accuracy: 0.5472\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6558 - accuracy: 0.5985 - val_loss: 0.6451 - val_accuracy: 0.6582\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6304 - accuracy: 0.7175 - val_loss: 0.6209 - val_accuracy: 0.6823\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6042 - accuracy: 0.7764 - val_loss: 0.5954 - val_accuracy: 0.7699\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5776 - accuracy: 0.8125 - val_loss: 0.5704 - val_accuracy: 0.8265\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5516 - accuracy: 0.8336 - val_loss: 0.5473 - val_accuracy: 0.8424\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5271 - accuracy: 0.8438 - val_loss: 0.5244 - val_accuracy: 0.8438\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5043 - accuracy: 0.8507 - val_loss: 0.5037 - val_accuracy: 0.8450\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4833 - accuracy: 0.8563 - val_loss: 0.4875 - val_accuracy: 0.8263\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4639 - accuracy: 0.8583 - val_loss: 0.4683 - val_accuracy: 0.8444\n",
      "=== MODEL EVALUATE TEST DATA ===\n",
      "\n",
      "Validation Accuracy: 0.8443790674209595\n",
      "Validation Loss: 0.4683164358139038\n",
      "\n",
      "468/468 [==============================] - 3s 6ms/step\n",
      "using test size : 0.3\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8501    0.7988    0.8236      6803\n",
      "           1     0.8401    0.8825    0.8608      8150\n",
      "\n",
      "    accuracy                         0.8444     14953\n",
      "   macro avg     0.8451    0.8406    0.8422     14953\n",
      "weighted avg     0.8447    0.8444    0.8439     14953\n",
      "\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 15000, 32)         128       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 7500, 32)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 240000)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                7680032   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,680,193\n",
      "Trainable params: 7,680,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "546/546 [==============================] - 16s 28ms/step - loss: 0.6759 - accuracy: 0.5482 - val_loss: 0.6611 - val_accuracy: 0.5898\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6449 - accuracy: 0.6556 - val_loss: 0.6318 - val_accuracy: 0.6656\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6135 - accuracy: 0.7491 - val_loss: 0.6016 - val_accuracy: 0.7653\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5820 - accuracy: 0.8067 - val_loss: 0.5728 - val_accuracy: 0.7893\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5519 - accuracy: 0.8304 - val_loss: 0.5453 - val_accuracy: 0.8408\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5239 - accuracy: 0.8459 - val_loss: 0.5201 - val_accuracy: 0.8397\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4984 - accuracy: 0.8531 - val_loss: 0.4976 - val_accuracy: 0.8448\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4758 - accuracy: 0.8578 - val_loss: 0.4777 - val_accuracy: 0.8467\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4558 - accuracy: 0.8593 - val_loss: 0.4601 - val_accuracy: 0.8490\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4377 - accuracy: 0.8620 - val_loss: 0.4450 - val_accuracy: 0.8502\n",
      "=== MODEL EVALUATE TEST DATA ===\n",
      "\n",
      "Validation Accuracy: 0.8501972556114197\n",
      "Validation Loss: 0.4449518322944641\n",
      "\n",
      "468/468 [==============================] - 3s 6ms/step\n",
      "using test size : 0.3\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8845    0.7714    0.8241      6803\n",
      "           1     0.8276    0.9160    0.8695      8150\n",
      "\n",
      "    accuracy                         0.8502     14953\n",
      "   macro avg     0.8561    0.8437    0.8468     14953\n",
      "weighted avg     0.8535    0.8502    0.8489     14953\n",
      "\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 15000, 32)         128       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 7500, 32)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 240000)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                7680032   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,680,193\n",
      "Trainable params: 7,680,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "546/546 [==============================] - 16s 28ms/step - loss: 0.6781 - accuracy: 0.5520 - val_loss: 0.6644 - val_accuracy: 0.5651\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6503 - accuracy: 0.6293 - val_loss: 0.6386 - val_accuracy: 0.6660\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6227 - accuracy: 0.7360 - val_loss: 0.6122 - val_accuracy: 0.7703\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5949 - accuracy: 0.7938 - val_loss: 0.5862 - val_accuracy: 0.8188\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5678 - accuracy: 0.8248 - val_loss: 0.5611 - val_accuracy: 0.8277\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5420 - accuracy: 0.8395 - val_loss: 0.5376 - val_accuracy: 0.8392\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5178 - accuracy: 0.8500 - val_loss: 0.5160 - val_accuracy: 0.8455\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4955 - accuracy: 0.8557 - val_loss: 0.4963 - val_accuracy: 0.8474\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4750 - accuracy: 0.8600 - val_loss: 0.4789 - val_accuracy: 0.8424\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4566 - accuracy: 0.8609 - val_loss: 0.4620 - val_accuracy: 0.8485\n",
      "=== MODEL EVALUATE TEST DATA ===\n",
      "\n",
      "Validation Accuracy: 0.8485254049301147\n",
      "Validation Loss: 0.46203020215034485\n",
      "\n",
      "468/468 [==============================] - 3s 6ms/step\n",
      "using test size : 0.3\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8856    0.7660    0.8215      6803\n",
      "           1     0.8245    0.9174    0.8685      8150\n",
      "\n",
      "    accuracy                         0.8485     14953\n",
      "   macro avg     0.8550    0.8417    0.8450     14953\n",
      "weighted avg     0.8523    0.8485    0.8471     14953\n",
      "\n",
      "\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 15000, 32)         128       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 7500, 32)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 240000)            0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                7680032   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,680,193\n",
      "Trainable params: 7,680,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "546/546 [==============================] - 16s 28ms/step - loss: 0.6762 - accuracy: 0.5645 - val_loss: 0.6608 - val_accuracy: 0.5872\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6449 - accuracy: 0.6621 - val_loss: 0.6316 - val_accuracy: 0.6985\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.6141 - accuracy: 0.7577 - val_loss: 0.6025 - val_accuracy: 0.7992\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5837 - accuracy: 0.8072 - val_loss: 0.5743 - val_accuracy: 0.8114\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5545 - accuracy: 0.8312 - val_loss: 0.5479 - val_accuracy: 0.8145\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5272 - accuracy: 0.8459 - val_loss: 0.5230 - val_accuracy: 0.8388\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.5021 - accuracy: 0.8521 - val_loss: 0.5009 - val_accuracy: 0.8411\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4797 - accuracy: 0.8567 - val_loss: 0.4811 - val_accuracy: 0.8463\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4593 - accuracy: 0.8575 - val_loss: 0.4640 - val_accuracy: 0.8446\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 0.4414 - accuracy: 0.8622 - val_loss: 0.4476 - val_accuracy: 0.8516\n",
      "=== MODEL EVALUATE TEST DATA ===\n",
      "\n",
      "Validation Accuracy: 0.8516016602516174\n",
      "Validation Loss: 0.44755691289901733\n",
      "\n",
      "468/468 [==============================] - 3s 6ms/step\n",
      "using test size : 0.3\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8830    0.7767    0.8265      6803\n",
      "           1     0.8306    0.9141    0.8704      8150\n",
      "\n",
      "    accuracy                         0.8516     14953\n",
      "   macro avg     0.8568    0.8454    0.8484     14953\n",
      "weighted avg     0.8545    0.8516    0.8504     14953\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size = [0.3]\n",
    "max_features = [15000]\n",
    "result = []\n",
    "count = 1\n",
    "for idx, value_testsize in enumerate(test_size):\n",
    "  for idx_max, value_features in enumerate(max_features):\n",
    "    for i in range(5):\n",
    "      result.append([count] + [value_testsize] + [value_features] + call(value_testsize, value_features))\n",
    "      count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def loss_func(df):\n",
    "  for idx, val in enumerate(df['No']):\n",
    "    plt.plot(df['Loss'].iloc[idx], label=f'Test Size {val}')\n",
    "    plt.plot(df['Val Loss'].iloc[idx], label=f'Test Size {val}')\n",
    "    plt.title(f'baseline BiGRU + CNN lfg {df[\"Test_Size\"].iloc[idx]} max_features {df[\"Max_Features\"].iloc[idx]}-{idx}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.savefig(f'hasil/grafik/bigru+cnn/lfg_baselineCNNBiGRU_testSize{df[\"Test_Size\"].iloc[idx]}-{idx}-max_features{df[\"Max_Features\"].iloc[idx]}.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score by Test Size\n",
      "Test Size 0.3 & max features 15000\n",
      "Average Accuracy Score : 0.8470273523707617\n",
      "Average Precision Score : 0.8252188944161472\n",
      "Average Recall Score : 0.9133006134969325\n",
      "Average F1 Score : 0.8455934269547992\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(result, columns=['No', 'Test_Size', 'Max_Features', 'Accuracy Score', 'Precision Score', 'Recall Score', 'F1 Score', 'Loss', 'Val Loss'])\n",
    "df.to_csv('hasil/baselineCNN-3-15000.csv', index=False)\n",
    "loss_func(df)\n",
    "# print average score by test size\n",
    "print('Average Score by Test Size')\n",
    "print('Test Size 0.3 & max features 15000')\n",
    "print('Average Accuracy Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 15000)]['Accuracy Score'].mean())\n",
    "print('Average Precision Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 15000)]['Precision Score'].mean())\n",
    "print('Average Recall Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 15000)]['Recall Score'].mean())\n",
    "print('Average F1 Score :', df[(df['Test_Size'] == 0.3) & (df['Max_Features'] == 15000)]['F1 Score'].mean())\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
